{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "WKbOIC4L7kHD",
        "7kY9a_uAZmyK",
        "OIzmOmeQR3zc",
        "ysbUbSZErUsw",
        "SOFzKDtNre1n",
        "wjk1FHuz7Hmm"
      ],
      "authorship_tag": "ABX9TyOfdqUGiuOWso63RxwiDYqP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/calm-ixia/SDManualGUI/blob/main/SDManualGUI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. ライブラリ導入"
      ],
      "metadata": {
        "id": "WKbOIC4L7kHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stable Diffusion パッケージのインストール \n",
        "# diffusersの公式リポジトリを参照 https://github.com/huggingface/diffusers\n",
        "# アカウント登録込みの作業フローは https://programmingforever.hatenablog.com/entry/2022/09/21/174953 も参考\n",
        "!pip install --upgrade diffusers transformers scipy ftfy\n",
        "!pip install accelerate\n",
        "\n",
        "#version 7.7.1 < latest 8.0.4\n",
        "from ipywidgets import widgets, Layout\n",
        "from PIL import Image, ImageChops\n",
        "from PIL.PngImagePlugin import PngInfo\n",
        "import io\n",
        "\n",
        "import torch\n",
        "import diffusers\n",
        "from diffusers import StableDiffusionPipeline, KarrasVePipeline, ScoreSdeVePipeline\n",
        "from diffusers.schedulers import *\n",
        "from diffusers.pipelines.stable_diffusion import StableDiffusionSafetyChecker\n",
        "\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "\n",
        "# xformersには未対応\n",
        "\"\"\"\n",
        "%pip install xformers==0.0.16rc425\n",
        "# https://note.com/npaka/n/n5fd3d8ecf1e6\n",
        "# %pip install -q https://github.com/metrolobo/xformers_wheels/releases/download/1d31a3ac_various_6/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl\n",
        "# http://cedro3.com/ai/dream-booth/\n",
        "#%pip install -q https://github.com/OMGhozlan/xformers_colab/releases/download/1.0.0/xformers-0.0.15.dev0+cu11.2-cp38-cp38-linux_x86_64.whl\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "Layered Diffusion (七師氏のStable Diffusion改造)\n",
        "  https://github.com/nanashi161382/unstable_diffusion\n",
        "  https://note.com/tomo161382/n/nff2aa749c48f\n",
        "\"\"\"\n",
        "!wget 'https://raw.githubusercontent.com/nanashi161382/unstable_diffusion/main/pipeline_layered_diffusion.py' -O /content/layered_diffusion.py\n",
        "\n",
        "import layered_diffusion\n",
        "\n",
        "\n",
        "# Long Prompt Weighting Stable Diffusion (SkyTNT氏) \n",
        "# https://github.com/huggingface/diffusers/tree/main/examples/community#long-prompt-weighting-stable-diffusion\n",
        "# community pipeline から オリジナルの lpw_stable_diffusion を直接利用する方法に変更した。以下の記述は参考として残す\n",
        "\n",
        "#if using_lpw_stable_diffusion_mod:\n",
        "#  # huggingfaceのAlanB氏のリポジトリにある、StableDiffusionLongPromptWeightingPipeline をインポート\n",
        "#  # https://huggingface.co/docs/hub/models-downloading\n",
        "#  %pip install huggingface_hub\n",
        "#  from huggingface_hub import hf_hub_url, hf_hub_download\n",
        "#  REPO_ID = \"AlanB/lpw_stable_diffusion_mod\"\n",
        "#  FILENAME = \"pipeline.py\"\n",
        "#  cache = hf_hub_download(repo_id=REPO_ID, filename=FILENAME)\n",
        "#!ln -s {cache} lpw_stable_diffusion_mod.py\n",
        "\n",
        "!wget 'https://raw.githubusercontent.com/huggingface/diffusers/main/examples/community/lpw_stable_diffusion.py' -O /content/lpw_stable_diffusion.py\n",
        "\n",
        "import lpw_stable_diffusion\n",
        "\n",
        "# Extras用のルートディレクトリ\n",
        "HighRes_root = \"/content/Real-ESRGAN\"\n",
        "DepthMap_root = \"/content/MiDaS\"\n"
      ],
      "metadata": {
        "id": "uOXie7PtOkrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# （必要時）割り当てられたGPUの確認"
      ],
      "metadata": {
        "id": "7kY9a_uAZmyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 割り当てられたGPUの確認\n",
        "!nvidia-smi\n",
        "\n",
        "#@markdown Googleドライブのマウント\n",
        "\"\"\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "QvXWjJ1sCIdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# （必要時）Hugging Face へのログイン\n",
        "Stable Diffusion 2.0, 2.1 では不要。runwayml-v1.5モデルの利用には利用同意とHugging Faceへのログインが要"
      ],
      "metadata": {
        "id": "OIzmOmeQR3zc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 利用同意が必要なモデルを利用する際に、Hugging Face に手動でログイン\n",
        "# その際に、アクセストークンをnotebookに保存せずに起動させるため、手動ログインを採用\n",
        "#@markdown Hugging Faceへのログインとは別に、利用モデルの利用規約を読んで同意(Agree and access repository)すること。\n",
        "#@markdown https://zenn.dev/razokulover/scraps/b4f639228ab305\n",
        "\n",
        "!huggingface-cli login\n"
      ],
      "metadata": {
        "id": "3akYS3L1R3zv",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# （必要時）高解像度化ライブラリReal-ESRGANの導入"
      ],
      "metadata": {
        "id": "ysbUbSZErUsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 公式のReadmeよりコピー\n",
        "\n",
        "# Clone repo\n",
        "!git clone https://github.com/xinntao/Real-ESRGAN.git\n",
        "%cd {HighRes_root}\n",
        "\n",
        "# Install dependent packages\n",
        "# Install basicsr - https://github.com/xinntao/BasicSR\n",
        "# We use BasicSR for both training and inference\n",
        "!pip install basicsr\n",
        "# facexlib and gfpgan are for face enhancement\n",
        "!pip install facexlib\n",
        "!pip install gfpgan\n",
        "!pip install -r requirements.txt\n",
        "!python setup.py develop\n",
        "\n",
        "import argparse\n",
        "import cv2\n",
        "import glob\n",
        "import os\n",
        "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
        "from basicsr.utils.download_util import load_file_from_url\n",
        "\n",
        "from realesrgan import RealESRGANer\n",
        "from realesrgan.archs.srvgg_arch import SRVGGNetCompact\n",
        "\n",
        "%cd /content\n"
      ],
      "metadata": {
        "id": "DEHVNaljr68R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# （必要時）深度推定ライブラリMiDaSの導入\n",
        "\n"
      ],
      "metadata": {
        "id": "SOFzKDtNre1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!git clone https://github.com/isl-org/MiDaS.git\n",
        "%cd {DepthMap_root}\n",
        "\n",
        "# requirements.yaml を基にpipでインストール\n",
        "!pip install cudatoolkit\n",
        "#!pip install pytorch\n",
        "!pip install torchvision\n",
        "#!pip install numpy\n",
        "!pip install opencv-python\n",
        "!pip install imutils\n",
        "!pip install timm\n",
        "!pip install einops\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import torch\n",
        "import utils\n",
        "import cv2\n",
        "import argparse\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from imutils.video import VideoStream\n",
        "import midas\n",
        "from midas.model_loader import default_models, load_model\n",
        "\n",
        "#from . import run\n",
        "from run import process, create_side_by_side\n",
        "\n",
        "%cd /content\n"
      ],
      "metadata": {
        "id": "H_Xox-OFrOHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. GUI実装"
      ],
      "metadata": {
        "id": "wjk1FHuz7Hmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ユーティリティ\n",
        "\n",
        "# 共通の処理\n",
        "\n",
        "# バッチ1回で生成した個々の画像オブジェクトと、バッチ1回分のgrid画像オブジェクトを生成\n",
        "def create_batch_image(outImages, width, height, grid_column_count):\n",
        "  #gridを生成\n",
        "  image_count = len(outImages)\n",
        "  grid_whole_width = width * grid_column_count\n",
        "  # バッチ1回ごとにグリッドの列数×行数の矩形を作る。余りが出る場合は黒塗りになる\n",
        "  grid_whole_height = height * math.ceil(image_count/grid_column_count)\n",
        "  grid_image = Image.new('RGB', size=(grid_whole_width, grid_whole_height) )\n",
        "\n",
        "  #画像ファイルを保存\n",
        "  # バッチ1回での行数\n",
        "  batch_rows = 1 + ((image_count-1)//grid_column_count)\n",
        "  for batch_index,image in enumerate(outImages):\n",
        "    # gridの所定位置にペースト\n",
        "    paste_col_index = batch_index % grid_column_count\n",
        "    paste_row_index = batch_index//grid_column_count\n",
        "    grid_image.paste(image, box=(width*paste_col_index, height*paste_row_index) )\n",
        "  \n",
        "  return grid_image\n",
        "\n",
        "# 画像をファイルに保存\n",
        "def save_image(image, fp, parameter_text):\n",
        "  # 画像のタグ情報を生成\n",
        "  grid_info = PngInfo()\n",
        "  grid_info.add_text(\"parameters\", parameter_text)\n",
        "  # gridをファイルに保存\n",
        "  image.save(fp, format=\"png\", pnginfo=grid_info)\n",
        "\n",
        "# サムネイルを作成、画像を縮小\n",
        "def create_thumbnail(image, resize=0.125):\n",
        "  return image.resize(size=(int(image.width*resize),int(image.height*resize)) )\n",
        "\n",
        "\"\"\"\n",
        "ipywidgets version 7.7.1の場合、\n",
        "widgets.FileUpload から得られる値は、\n",
        "{filename: {\"metadata\":{}, \"content\":rawdata} } の構造を持つdict\n",
        "\"\"\"\n",
        "def update_pnginfo(new_value):\n",
        "  # ipywidgets version 7.7.1での記述\n",
        "  for filename, value in new_value.items():\n",
        "    #metadata = value[\"metadata\"]\n",
        "\n",
        "    #rawデータを取得\n",
        "    data = value[\"content\"]\n",
        "    #画像情報取得用にPILのライブラリで画像を開く\n",
        "    img = Image.open(io.BytesIO(data))\n",
        "    #画像情報を取得\n",
        "    parameter_text = img.info[\"parameters\"]\n",
        "    return (data, parameter_text)\n",
        "\n",
        "def fileUploader_load_png(new_value):\n",
        "  for filename, value in new_value.items():\n",
        "    #print(value)\n",
        "    #print(list(value.keys()))\n",
        "    #metadata = value[\"metadata\"]\n",
        "    #print(metadata)\n",
        "\n",
        "    #rawデータを取得(bytesオブジェクト)\n",
        "    data = value[\"content\"]\n",
        "    return data\n",
        "\n",
        "\"\"\"\n",
        "TODO: widgets.FileUploadは ver.8でデータ構造が変更されているため、\n",
        "Colabのipywidgetsのバージョンがver.8以上になった場合はコードを変更すること。\n",
        "https://ipywidgets.readthedocs.io/en/stable/examples/Widget%20List.html#File-Upload\n",
        "\n",
        "ver.8 では、valueの値はファイルごとのdictのタプルとなる\n",
        "uploader.value = (\n",
        "   {\n",
        "     'name': 'example.txt',\n",
        "     'type': 'text/plain',\n",
        "     'size': 36,\n",
        "     'last_modified': datetime.datetime(2020, 1, 9, 15, 58, 43, 321000, tzinfo=datetime.timezone.utc),\n",
        "     'content': <memory at 0x10c1b37c8> # raw data, python 'memoryview' object\n",
        "   },\n",
        "   ...\n",
        ")\n",
        "\"\"\"\n",
        "pass\n"
      ],
      "metadata": {
        "id": "-QeWYHOP7edo",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Long Prompt Weighting とマスク操作\n",
        "\n",
        "# ロード済みのLong Prompt Weighting Pipelineを用いてtext embeddingを生成\n",
        "# Pipelineの_encode_prompt()だけ使用\n",
        "\n",
        "from typing import Callable, List, Optional, Union\n",
        "from diffusers import DiffusionPipeline\n",
        "from diffusers.pipelines.stable_diffusion import StableDiffusionPipelineOutput\n",
        "from diffusers.models import AutoencoderKL, UNet2DConditionModel\n",
        "from transformers import CLIPFeatureExtractor, CLIPTextModel, CLIPTokenizer\n",
        "import PIL\n",
        "\n",
        "class LPWEncoding(layered_diffusion.StandardEncoding):\n",
        "  def __init__(self,\n",
        "    lpw_pipe, #あらかじめモデルをロードしておく\n",
        "    num_images_per_prompt: Optional[int] = 1,\n",
        "    max_embeddings_multiples: Optional[int] = 3\n",
        "  ):\n",
        "    self.pipe = lpw_pipe\n",
        "    self.num_images_per_prompt = num_images_per_prompt\n",
        "    self.max_embeddings_multiples = max_embeddings_multiples\n",
        "\n",
        "  def Encode(self, text_model: layered_diffusion.TextModel, text: str, default_encoding:layered_diffusion.StandardEncoding):\n",
        "      # text_model, default_encodingは不使用。引数の仕様を合わせるだけのプレースホルダ\n",
        "      print(\"using LPWEncoding\")\n",
        "      # 与えらえたpromptだけをencodeする\n",
        "      return self.pipe._encode_prompt(\n",
        "        prompt=text,\n",
        "        device=self.pipe._execution_device,\n",
        "        num_images_per_prompt=self.num_images_per_prompt,\n",
        "        do_classifier_free_guidance=False, # promptのembeddingだけ欲しい\n",
        "        negative_prompt=None,\n",
        "        max_embeddings_multiples=self.max_embeddings_multiples,\n",
        "      )\n",
        "\n",
        "# Long Prompt Weighting にマスク操作を追加\n",
        "class StableDiffusionLPWMaskPipeline(lpw_stable_diffusion.StableDiffusionLongPromptWeightingPipeline):\n",
        "  def __init__(\n",
        "      self,\n",
        "      vae: AutoencoderKL,\n",
        "      text_encoder: CLIPTextModel,\n",
        "      tokenizer: CLIPTokenizer,\n",
        "      unet: UNet2DConditionModel,\n",
        "      scheduler: SchedulerMixin,\n",
        "      safety_checker: StableDiffusionSafetyChecker,\n",
        "      feature_extractor: CLIPFeatureExtractor,\n",
        "      requires_safety_checker: bool = True,\n",
        "  ):\n",
        "      super().__init__(\n",
        "          vae=vae,\n",
        "          text_encoder=text_encoder,\n",
        "          tokenizer=tokenizer,\n",
        "          unet=unet,\n",
        "          scheduler=scheduler,\n",
        "          safety_checker=safety_checker,\n",
        "          feature_extractor=feature_extractor,\n",
        "          requires_safety_checker=requires_safety_checker,\n",
        "      )\n",
        "      \n",
        "  def prepare_latents(self, image, timestep, batch_size, height, width, dtype, device, generator, latents=None):\n",
        "    init_latents_orig = None\n",
        "    noise = None\n",
        "\n",
        "    if image is None:\n",
        "      shape = (\n",
        "          batch_size,\n",
        "          self.unet.in_channels,\n",
        "          height // self.vae_scale_factor,\n",
        "          width // self.vae_scale_factor,\n",
        "      )\n",
        "\n",
        "      if latents is None:\n",
        "        # txt2img\n",
        "        #print(\"prepare_latents: for txt2img\")\n",
        "        if device.type == \"mps\":\n",
        "            # randn does not work reproducibly on mps\n",
        "            latents = torch.randn(shape, generator=generator, device=\"cpu\", dtype=dtype).to(device)\n",
        "        else:\n",
        "            latents = torch.randn(shape, generator=generator, device=device, dtype=dtype)\n",
        "        latents = latents * self.scheduler.init_noise_sigma\n",
        "        return latents, None, None\n",
        "      else:\n",
        "        # img2img using latents\n",
        "        #print(\"prepare_latents: for img2img using latents\")\n",
        "        if latents.shape != shape:\n",
        "          raise ValueError(f\"Unexpected latents shape, got {latents.shape}, expected {shape}\")\n",
        "        latents = latents.to(device)\n",
        "        # scale the initial noise by the standard deviation required by the scheduler\n",
        "        latents = latents * self.scheduler.init_noise_sigma\n",
        "        init_latents_orig = latents\n",
        "        init_latents = torch.cat([latents], dim=0) # make a copy\n",
        "\n",
        "    else:\n",
        "      # img2img using an image\n",
        "      #print(\"prepare_latents: for img2img using an image\")\n",
        "      init_latent_dist = self.vae.encode(image).latent_dist\n",
        "      init_latents = init_latent_dist.sample(generator=generator)\n",
        "      init_latents = 0.18215 * init_latents\n",
        "      init_latents = torch.cat([init_latents] * batch_size, dim=0)\n",
        "      init_latents_orig = init_latents\n",
        "\n",
        "    # add noise to latents using the timesteps\n",
        "    shape = init_latents.shape\n",
        "    if device.type == \"mps\":\n",
        "        noise = torch.randn(shape, generator=generator, device=\"cpu\", dtype=dtype).to(device)\n",
        "    else:\n",
        "        noise = torch.randn(shape, generator=generator, device=device, dtype=dtype)\n",
        "    latents = self.scheduler.add_noise(init_latents, noise, timestep)\n",
        "\n",
        "    return latents, init_latents_orig, noise\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def __call__(\n",
        "      self,\n",
        "      prompt: Union[str, List[str]],\n",
        "      negative_prompt: Optional[Union[str, List[str]]] = None,\n",
        "      image: Union[torch.FloatTensor, PIL.Image.Image] = None,\n",
        "      mask_image: Union[torch.FloatTensor, PIL.Image.Image] = None,\n",
        "      height: int = 512,\n",
        "      width: int = 512,\n",
        "      num_inference_steps: int = 50,\n",
        "      guidance_scale: float = 7.5,\n",
        "      strength: float = 0.8,\n",
        "      num_images_per_prompt: Optional[int] = 1,\n",
        "      eta: float = 0.0,\n",
        "      generator: Optional[torch.Generator] = None,\n",
        "      latents: Optional[torch.FloatTensor] = None,\n",
        "      max_embeddings_multiples: Optional[int] = 3,\n",
        "      output_type: Optional[str] = \"pil\",\n",
        "      return_dict: bool = True,\n",
        "      callback: Optional[Callable[[int, int, torch.FloatTensor], None]] = None,\n",
        "      is_cancelled_callback: Optional[Callable[[], bool]] = None,\n",
        "      callback_steps: Optional[int] = 1,\n",
        "      mask_timing: Optional[str] = \"last\",\n",
        "      mask_output:bool = True,\n",
        "      **kwargs,\n",
        "  ):\n",
        "      \"\"\" 追加引数:\n",
        "        mask_output = True : 最終出力にマスクをかけるかどうか\n",
        "        mask_timing: Optional[\"last\", \"first\", \"none\"] = \"last\" : 生成ステップ内でマスクをかけるタイミング。絵柄が少し変化する\n",
        "          \"last\": Diffusersベース。デノイズ後、ステップの最後にadd_noise()＆マスクを行い、次のステップの入力に渡す。背景が崩れやすいため mask_output=True と併用すると良い\n",
        "          \"first\": AUTOMATIC1111 web UIに似た方法。ステップの最初にadd_noise()＆マスクし、その後デノイズする。背景が残りつつ画質が良い\n",
        "          \"none\": ステップ中にマスクをかけない。背景が大きく書き換わるが画質は良い。mask_output=False と併用すると良い画が得られる\n",
        "      \"\"\"\n",
        "      if (mask_timing is not None) and not (mask_timing in [\"last\", \"first\", \"none\"]):\n",
        "          raise ValueError(f\"mask_timing got {mask_timing} , expected 'last', 'first' or 'none' \")\n",
        "\n",
        "      # 0. Default height and width to unet\n",
        "      height = height or self.unet.config.sample_size * self.vae_scale_factor\n",
        "      width = width or self.unet.config.sample_size * self.vae_scale_factor\n",
        "\n",
        "      # 1. Check inputs. Raise error if not correct\n",
        "      self.check_inputs(prompt, height, width, strength, callback_steps)\n",
        "\n",
        "      # 2. Define call parameters\n",
        "      batch_size = 1 if isinstance(prompt, str) else len(prompt)\n",
        "      device = self._execution_device\n",
        "      # here `guidance_scale` is defined analog to the guidance weight `w` of equation (2)\n",
        "      # of the Imagen paper: https://arxiv.org/pdf/2205.11487.pdf . `guidance_scale = 1`\n",
        "      # corresponds to doing no classifier free guidance.\n",
        "      do_classifier_free_guidance = guidance_scale > 1.0\n",
        "\n",
        "      # 3. Encode input prompt\n",
        "      text_embeddings = self._encode_prompt(\n",
        "          prompt,\n",
        "          device,\n",
        "          num_images_per_prompt,\n",
        "          do_classifier_free_guidance,\n",
        "          negative_prompt,\n",
        "          max_embeddings_multiples,\n",
        "      )\n",
        "      dtype = text_embeddings.dtype\n",
        "\n",
        "      # 4. Preprocess image and mask\n",
        "      if isinstance(image, PIL.Image.Image):\n",
        "          image = lpw_stable_diffusion.preprocess_image(image)\n",
        "      if image is not None:\n",
        "          image = image.to(device=self.device, dtype=dtype)\n",
        "      if isinstance(mask_image, PIL.Image.Image):\n",
        "          mask_image = lpw_stable_diffusion.preprocess_mask(mask_image, self.vae_scale_factor)\n",
        "      if mask_image is not None:\n",
        "          mask = mask_image.to(device=self.device, dtype=dtype)\n",
        "          mask = torch.cat([mask] * batch_size * num_images_per_prompt)\n",
        "      else:\n",
        "          mask = None\n",
        "\n",
        "      # 5. set timesteps\n",
        "      self.scheduler.set_timesteps(num_inference_steps, device=device)\n",
        "      timesteps, num_inference_steps = self.get_timesteps(num_inference_steps, strength, device, image is None)\n",
        "      latent_timestep = timesteps[:1].repeat(batch_size * num_images_per_prompt)\n",
        "\n",
        "      # 6. Prepare latent variables\n",
        "      latents, init_latents_orig, noise = self.prepare_latents(\n",
        "          image,\n",
        "          latent_timestep,\n",
        "          batch_size * num_images_per_prompt,\n",
        "          height,\n",
        "          width,\n",
        "          dtype,\n",
        "          device,\n",
        "          generator,\n",
        "          latents,\n",
        "      )\n",
        "\n",
        "      # 7. Prepare extra step kwargs. TODO: Logic should ideally just be moved out of the pipeline\n",
        "      extra_step_kwargs = self.prepare_extra_step_kwargs(generator, eta)\n",
        "\n",
        "      self.diffusers_style = False\n",
        "      # 8. Denoising loop\n",
        "      for i, t in enumerate(self.progress_bar(timesteps)):\n",
        "\n",
        "          # AUTOMATIC1111 style, adding noise at the first\n",
        "          if mask_timing == \"first\":\n",
        "            if mask is not None:\n",
        "                # masking\n",
        "                init_latents_proper = self.scheduler.add_noise(init_latents_orig, noise, torch.tensor([t]))\n",
        "                latents = (init_latents_proper * mask) + (latents * (1 - mask))\n",
        "\n",
        "          # expand the latents if we are doing classifier free guidance\n",
        "          latent_model_input = torch.cat([latents] * 2) if do_classifier_free_guidance else latents\n",
        "          latent_model_input = self.scheduler.scale_model_input(latent_model_input, t)\n",
        "\n",
        "          # predict the noise residual\n",
        "          noise_pred = self.unet(latent_model_input, t, encoder_hidden_states=text_embeddings).sample\n",
        "\n",
        "          # perform guidance\n",
        "          if do_classifier_free_guidance:\n",
        "              noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
        "              noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
        "\n",
        "          # compute the previous noisy sample x_t -> x_t-1\n",
        "          latents = self.scheduler.step(noise_pred, t, latents, **extra_step_kwargs).prev_sample\n",
        "\n",
        "          # diffusers and unstable diffusion style, adding noise at the last\n",
        "          if mask_timing == \"last\":\n",
        "            # in the implementation of unstable_diffusion, skipping the adding noise at the last step\n",
        "            if (mask is not None) and (i < len(timesteps)-1 ):\n",
        "                # masking\n",
        "                init_latents_proper = self.scheduler.add_noise(init_latents_orig, noise, torch.tensor([t]))\n",
        "                latents = (init_latents_proper * mask) + (latents * (1 - mask))\n",
        "\n",
        "          # call the callback, if provided\n",
        "          if i % callback_steps == 0:\n",
        "              if callback is not None:\n",
        "                  callback(i, t, latents)\n",
        "              if is_cancelled_callback is not None and is_cancelled_callback():\n",
        "                  return None\n",
        "\n",
        "      # 9. Post-processing\n",
        "\n",
        "      # mask directly (both unstable diffusion and AUTOMATIC1111)\n",
        "      if (mask is not None) and (mask_output == True):\n",
        "          # masking\n",
        "          latents = (init_latents_orig * mask) + (latents * (1 - mask))\n",
        "\n",
        "      image = self.decode_latents(latents)\n",
        "\n",
        "      # 10. Run safety checker\n",
        "      image, has_nsfw_concept = self.run_safety_checker(image, device, text_embeddings.dtype)\n",
        "\n",
        "      # 11. Convert to PIL\n",
        "      if output_type == \"pil\":\n",
        "          image = self.numpy_to_pil(image)\n",
        "\n",
        "      if not return_dict:\n",
        "          return image, has_nsfw_concept\n",
        "\n",
        "      return StableDiffusionPipelineOutput(images=image, nsfw_content_detected=has_nsfw_concept)\n",
        "\n"
      ],
      "metadata": {
        "id": "j1KXV9_IiYnl",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 画像生成モジュール用のデータコンテナ\n",
        "\n",
        "import copy\n",
        "from distutils.util import strtobool\n",
        "\n",
        "class GeneratedFileInfo:\n",
        "  def __init__(self, prompt=\"\", negative_prompt=\"\",\n",
        "    scheduler_name=\"\", step_count=0, guidance_scale=0, seed=0, width=0, height=0,\n",
        "    batch_size=0, batch_count=0, grid_column_count=0, enable_safety_checker=True, eta=0.0, resize=0.25, latents_type=None, extra_param = {}\n",
        "  ):\n",
        "    self.path = \"\"\n",
        "    self.thumbnailBytes: bytes = None\n",
        "    self.imageBytes: bytes = None\n",
        "    # set parameters\n",
        "    self.prompt = prompt\n",
        "    self.negative_prompt = negative_prompt\n",
        "    self.scheduler_name = scheduler_name\n",
        "    self.step_count = step_count\n",
        "    self.guidance_scale = guidance_scale\n",
        "    self.seed = seed\n",
        "    self.width = width\n",
        "    self.height = height\n",
        "    self.batch_size = batch_size\n",
        "    self.batch_count = batch_count\n",
        "    self.grid_column_count = grid_column_count\n",
        "    self.enable_safety_checker = enable_safety_checker\n",
        "    self.eta = eta\n",
        "    self.resize = resize\n",
        "    self.latents_type = latents_type\n",
        "    self.extra_param = extra_param\n",
        "\n",
        "  def clone(self):\n",
        "    cloned = self.clone_light()\n",
        "    cloned.extra_param = copy.deepcopy(self.extra_param)\n",
        "    return cloned\n",
        "\n",
        "  # バイナリデータ(imageBytes, thumbnailBytes, extra_param['image'], extra_param['mask_image'], extra_param['latents'])はコピーしないので必要に応じてコピーすること\n",
        "  def clone_light(self):\n",
        "    cloned = GeneratedFileInfo()\n",
        "    cloned.path = copy.deepcopy(self.path)\n",
        "    # set parameters\n",
        "    cloned.prompt = copy.deepcopy(self.prompt)\n",
        "    cloned.negative_prompt = copy.deepcopy(self.negative_prompt)\n",
        "    cloned.scheduler_name = copy.deepcopy(self.scheduler_name)\n",
        "    cloned.step_count = copy.deepcopy(self.step_count)\n",
        "    cloned.guidance_scale = copy.deepcopy(self.guidance_scale)\n",
        "    cloned.seed = copy.deepcopy(self.seed)\n",
        "    cloned.width = copy.deepcopy(self.width)\n",
        "    cloned.height = copy.deepcopy(self.height)\n",
        "    cloned.batch_size = copy.deepcopy(self.batch_size)\n",
        "    cloned.batch_count = copy.deepcopy(self.batch_count)\n",
        "    cloned.grid_column_count = copy.deepcopy(self.grid_column_count)\n",
        "    cloned.enable_safety_checker = copy.deepcopy(self.enable_safety_checker)\n",
        "    cloned.eta = copy.deepcopy(self.eta)\n",
        "    cloned.resize = copy.deepcopy(self.resize)\n",
        "    cloned.latents_type = copy.deepcopy(self.latents_type)\n",
        "    # extra_paramのうちバイナリデータではないものを複製\n",
        "    for key,val in self.extra_param.items():\n",
        "      if key in [\"image\", \"mask_image\", \"latents\"]:\n",
        "        continue\n",
        "      cloned.extra_param[key] = copy.deepcopy(val)\n",
        "    \n",
        "    return cloned\n",
        "    \n",
        "  # 埋め込み用のパラメータ文字列を生成\n",
        "  def create_parameter_text(self):\n",
        "  #    f\"Steps: {step_count}, Sampler: {scheduler_name}, CFG scale: {guidance_scale}, Seed: {seed}, Size: {width}x{height}, Model hash: {a2a802b2}\",\n",
        "    param = \", \".join([\n",
        "      f\"Steps: {self.step_count}\",\n",
        "      f\"Sampler: {self.scheduler_name}\",\n",
        "      f\"CFG scale: {self.guidance_scale}\",\n",
        "      f\"Seed: {self.seed}\",\n",
        "      f\"Size: {self.width}x{self.height}\",\n",
        "    ])\n",
        "    if 'strength' in self.extra_param:\n",
        "      param += f\", Denoising strength: {self.extra_param['strength']}\"\n",
        "    if self.latents_type is not None:\n",
        "      param += f\", Masked content: {self.latents_type}\"\n",
        "    if 'mask_timing' in self.extra_param:\n",
        "      param += f\", Mask timing: {self.extra_param['mask_timing']}\"\n",
        "    if 'mask_output' in self.extra_param:\n",
        "      param += f\", Mask output: {self.extra_param['mask_output']}\"\n",
        "\n",
        "    return \"\\n\".join([\n",
        "      self.prompt,\n",
        "      f\"Negative prompt: {self.negative_prompt}\",\n",
        "      param\n",
        "    ])\n",
        "\n",
        "  @classmethod\n",
        "  def parse_parameter_text(cls, parameter_text):\n",
        "    param_dict = dict()\n",
        "\n",
        "    negative_prompt_begin = parameter_text.find(\"Negative prompt: \")\n",
        "    # \"Negative prompt:\" の直前までが通常のプロンプト\n",
        "    prompt = parameter_text[0:negative_prompt_begin]\n",
        "    param_dict['Prompt'] = prompt\n",
        "    other_str = parameter_text[negative_prompt_begin:len(parameter_text)]\n",
        "\n",
        "    # \"Steps:\" の直前までがネガティブプロンプト\n",
        "    step_begin = parameter_text.find(\"Steps:\")\n",
        "    negative_prompt_pair = parameter_text[negative_prompt_begin:step_begin]\n",
        "    negative_prompt = negative_prompt_pair.replace('Negative prompt: ', '', 1)\n",
        "    param_dict['Negative prompt'] = negative_prompt\n",
        "\n",
        "    # \"foo: **, \" の形式で設定パラメータが続く\n",
        "    param_dict_str = parameter_text[step_begin:len(parameter_text)]\n",
        "    param_pairs = param_dict_str.split(',')\n",
        "    for pair in param_pairs:\n",
        "      kv = pair.split(':')\n",
        "      if len(kv) == 2:\n",
        "        key,value = kv\n",
        "        # ,:の区切りで分割するだけだと先頭や末尾に空白が残るので、それらを除去\n",
        "        # 'Euler a' のように語中に空白があるケースもあるので、replace()ではなくstrip()を使用\n",
        "        param_key = key.strip()\n",
        "        param_value = value.strip()\n",
        "        param_dict[param_key] =param_value\n",
        "      else:\n",
        "        print(f\"Warning: skip key-value {kv}\")\n",
        "      \n",
        "    # 必要に応じて数値文字列を数値に変換\n",
        "    conv = {\n",
        "      'Prompt': lambda x: x,\n",
        "      'Negative prompt': lambda x: x,\n",
        "      'Steps': lambda x: int(x),\n",
        "      'Sampler': lambda x: x, # 文字列をそのまま取得\n",
        "      'CFG scale': lambda x: float(x),\n",
        "      'Seed': lambda x: int(x),\n",
        "      # Sizeをタプルに変換。 \"Size: 512x512\" のように記述されている\n",
        "      'Size': lambda x: tuple([int(s) for s in x.split('x')]),\n",
        "      'Denoising strength': lambda x: float(x),\n",
        "      'Masked content': lambda x: x,\n",
        "      'Mask timing': lambda x: x,\n",
        "      'Mask output': lambda x: bool(strtobool(x)),\n",
        "    }\n",
        "\n",
        "    result = dict()\n",
        "    for key,val in param_dict.items():\n",
        "      if key in conv:\n",
        "        result[key] = conv[key](val)\n",
        "    \n",
        "    return result\n",
        "\n",
        "  @classmethod\n",
        "  def from_parameter_text(cls, parameter_text):\n",
        "    param_dict = cls.parse_parameter_text(parameter_text)\n",
        "    latents_type = None\n",
        "    extra_param = {}\n",
        "    if 'Denoising strength' in param_dict:\n",
        "      extra_param['strength'] = param_dict['Denoising strength']\n",
        "    if 'Masked content' in param_dict:\n",
        "      latents_type = param_dict['Masked content']\n",
        "    if 'Mask timing' in param_dict:\n",
        "      extra_param['mask_timing'] = param_dict['Mask timing']\n",
        "    if 'Mask output' in param_dict:\n",
        "      extra_param['mask_output'] = param_dict['Mask output']\n",
        "\n",
        "    return GeneratedFileInfo(\n",
        "      prompt = param_dict['Prompt'],\n",
        "      negative_prompt = param_dict['Negative prompt'],\n",
        "      scheduler_name = param_dict['Sampler'],\n",
        "      step_count = param_dict['Steps'],\n",
        "      guidance_scale = param_dict['CFG scale'],\n",
        "      seed = param_dict['Seed'],\n",
        "      width = param_dict['Size'][0],\n",
        "      height = param_dict['Size'][1],\n",
        "      #batch_size = param_dict[''],\n",
        "      #batch_count = param_dict[''],\n",
        "      #grid_column_count = param_dict[''],\n",
        "      #enable_safety_checker = param_dict[''],\n",
        "      #eta = param_dict[''],\n",
        "      latents_type = latents_type,\n",
        "      extra_param = extra_param,\n",
        "    )\n",
        "\n",
        "  def save_image(self, image, filepath):\n",
        "    parameter_text = self.create_parameter_text()\n",
        "    save_image(image, filepath, parameter_text)\n",
        "    with io.BytesIO() as buf:\n",
        "      save_image(image, buf, parameter_text)\n",
        "      self.imageBytes = buf.getvalue()\n",
        "\n",
        "  def save_thumbnail(self, image, resize):\n",
        "    parameter_text = self.create_parameter_text()\n",
        "    thumbnail = image.resize(size=(int(image.width*resize),int(image.height*resize)) )\n",
        "    with io.BytesIO() as buf:\n",
        "      save_image(thumbnail, buf, parameter_text)\n",
        "      self.thumbnailBytes = buf.getvalue()\n",
        "\n"
      ],
      "metadata": {
        "id": "gBo1RJN0jQir",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.modeling_utils import init_empty_weights\n",
        "#@title 画像生成モジュール\n",
        "\n",
        "class BackEnd:\n",
        "  def __init__(self):\n",
        "    # LayeredDiffusionPipelineのConnect()による設定ではモデルのリビジョン違い等に対応できないため、手動でPipelineをセットアップ\n",
        "    self.pipe: StableDiffusionPipeline = None\n",
        "    self.pipeBuilder: layered_diffusion.LayeredDiffusionPipeline = None\n",
        "    self.model = \"\"\n",
        "    self.revision = \"\"\n",
        "    self.device_to = \"\"\n",
        "    self.attention_slicing = False\n",
        "    self.safety_checker = False\n",
        "    self.xformers_memory_efficient_attention = False\n",
        "    # ファイル名につかう時間文字列のフォーマット\n",
        "    self.timestr_format=\"%H%M%S_%y%b%d\"\n",
        "    # 更新するペイン\n",
        "    self.setupPane = None\n",
        "    self.txt2imgPane = None\n",
        "    self.img2imgPane = None\n",
        "    self.inpaintPane = None\n",
        "    self.pnginfoPane = None\n",
        "    \n",
        "    # サンプリング手法（ノイズ除去スケジューラ）\n",
        "    # https://huggingface.co/docs/diffusers/api/schedulers#implemented-schedulers\n",
        "    # diffuserでは PNDM Scheduler がデフォルト\n",
        "    # https://huggingface.co/blog/stable_diffusion\n",
        "    # https://torch.classcat.com/2022/11/13/huggingface-blog-stable-diffusion/\n",
        "\n",
        "    #TODO: Karrasタイムステップを用いる手法のSchedulerを実装。特にk-DPM++2M Karras\n",
        "    self.schedulerDict = {\n",
        "        \"DPM++ 2M\": {\"SchedulerClass\":DPMSolverMultistepScheduler, \"desc\":\"Multistep DPM-Solver++ (DPM:diffusion probabilistic models)\"},\n",
        "        \"Euler a\": {\"SchedulerClass\":EulerAncestralDiscreteScheduler, \"desc\":\"Euler Ancestral scheduler  aka k-euler-a\"},\n",
        "        \"Euler\": {\"SchedulerClass\":EulerDiscreteScheduler, \"desc\":\"Euler scheduler  aka k-euler\"},\n",
        "        \"DPM\": {\"SchedulerClass\":DPMSolverMultistepScheduler, \"desc\":\"Multistep DPM-Solver (DPM:diffusion probabilistic models)\"},\n",
        "        \"DPM++ 2S\": {\"SchedulerClass\":DPMSolverSinglestepScheduler , \"desc\":\"Singlestep DPM-Solver++ (DPM:diffusion probabilistic models)\"},\n",
        "        \"DDIM\": {\"SchedulerClass\":DDIMScheduler, \"desc\":\"Denoising diffusion implicit models\"},\n",
        "        \"DDPM\": {\"SchedulerClass\":DDPMScheduler, \"desc\":\"Denoising diffusion probabilistic models\"},\n",
        "        \"PNDM\": {\"SchedulerClass\":PNDMScheduler, \"desc\":\"Pseudo numerical methods for diffusion models  runwayMLモデルのデフォルト\"},\n",
        "        \"IPNDM\": {\"SchedulerClass\":IPNDMScheduler, \"desc\":\"Improved Pseudo numerical methods for diffusion models\"},\n",
        "        \"LMS\": {\"SchedulerClass\":LMSDiscreteScheduler, \"desc\":\"Linear multistep scheduler for discrete beta schedules  aka k-LMS\"},\n",
        "        \"Heun 1\": {\"SchedulerClass\":HeunDiscreteScheduler, \"desc\":\"k-diffusion, Algorithm 1 of Karras et. al.\"},\n",
        "        \"KDPM2\": {\"SchedulerClass\":KDPM2DiscreteScheduler, \"desc\":\"DPM 2, log interpolation\"},\n",
        "        \"KDPM2 a\": {\"SchedulerClass\":KDPM2AncestralDiscreteScheduler, \"desc\":\"KDPM2 Ancestral\"},\n",
        "        \"KarrasVe\": {\"PipelineClass\":KarrasVePipeline, \"desc\":\"Variance exploding, stochastic sampling from Karras et. al\"},\n",
        "        \"ScoreSdeVe\": {\"PipelineClass\":ScoreSdeVePipeline, \"desc\":\"variance exploding stochastic differential equation (VE-SDE) scheduler\"},\n",
        "        #\"ScoreSdeVp\":  {\"PipelineClass\":, \"desc\":\"variance preserving stochastic differential equation (VP-SDE) scheduler\"},\n",
        "    }\n",
        "\n",
        "  def setup(self, model, revision, device_to, output_dir, default_width, default_height, attention_slicing, xformers_memory_efficient_attention, safety_checker, using_layered_diffusion):\n",
        "    self.model = model # \"stabilityai\" などのリポジトリ名\n",
        "    self.revision = revision # \"fp16\" などのリビジョン名\n",
        "    self.device_to = device_to\n",
        "    self.attention_slicing = attention_slicing\n",
        "    self.xformers_memory_efficient_attention = xformers_memory_efficient_attention #未対応、メンバのみ用意\n",
        "    self.safety_checker = safety_checker\n",
        "    self.safety_checker_obj = None\n",
        "    self.using_layered_diffusion = using_layered_diffusion\n",
        "    self.output_dir = output_dir\n",
        "\n",
        "    #ディレクトリを生成しておく\n",
        "    os.makedirs(self.output_dir, exist_ok=True)\n",
        "\n",
        "    # 画像生成に用いるスケジューラ（sampler）をあらかじめ生成しておく\n",
        "    #  It is deprecated to pass a pretrained model name or path to `from_config`.\n",
        "    #  If you were trying to load a scheduler, please use (Scheduluerクラス名).from_pretrained(...) instead. \n",
        "    # https://note.com/npaka/n/n5fd3d8ecf1e6 を参照した\n",
        "    for (k,v) in self.schedulerDict.items():\n",
        "      klass = self.schedulerDict[k]\n",
        "      if \"SchedulerClass\" in klass:\n",
        "        klass[\"scheduler\"] = klass[\"SchedulerClass\"].from_pretrained(model, subfolder=\"scheduler\")\n",
        "    \n",
        "    # construct a pipeline\n",
        "    # TODO:別のパイプラインを指定できるようにする（img2img, inpaint, KarrasVeなど）\n",
        "\n",
        "    self.pipe = StableDiffusionLPWMaskPipeline.from_pretrained(\n",
        "      self.model,\n",
        "      torch_dtype=torch.float16,\n",
        "      revision=self.revision,\n",
        "    ).to(self.device_to)\n",
        "\n",
        "    # safety_checkerを退避しておく    \n",
        "    self.safety_checker_obj = self.pipe.safety_checker\n",
        "    # ロード済みのcomponentsを持っておき、別のパイプラインに切り替える時に再利用する\n",
        "    self.components = self.pipe.components\n",
        "\n",
        "    # 所要時間が増える代わりにGPUメモリ使用量を抑える\n",
        "    if self.attention_slicing:\n",
        "      self.pipe.enable_attention_slicing()\n",
        "    # xformersによるメモリ軽減を図る\n",
        "    #if self.xformers_memory_efficient_attention:\n",
        "      #self.pipe.enable_xformers_memory_efficient_attention()\n",
        "\n",
        "    # LayeredDiffusionPipelineのConnect()による設定ではモデルのリビジョン違い等に対応できないため、手動でセットアップ\n",
        "    self.pipeBuilder = layered_diffusion.LayeredDiffusionPipeline()\n",
        "    #TODO: publicメソッドがあればそちらを使用する\n",
        "    self.pipeBuilder._dataset = self.model\n",
        "    self.pipeBuilder._SetPipeline(self.pipe)\n",
        "\n",
        "    #テキストエンコーダをセット\n",
        "    #self.textEncoder = layered_diffusion.ShiftEncoding(rotate=False, reverse=False)\n",
        "    self.textEncoder = LPWEncoding(self.pipe)\n",
        "\n",
        "    #txt2imgのサンプラーリストとwidth,height初期値を更新\n",
        "    self.txt2imgPane.set_param( list(self.schedulerDict.keys()), default_width, default_height )\n",
        "    self.img2imgPane.set_param( list(self.schedulerDict.keys()), default_width, default_height )\n",
        "    self.inpaintPane.set_param( list(self.schedulerDict.keys()), default_width, default_height )\n",
        "\n",
        "\n",
        "  def word_count(self, prompt):\n",
        "    if self.pipe is None:\n",
        "      return 0\n",
        "    untruncated_ids = self.pipe.tokenizer(prompt, padding=\"longest\", return_tensors=\"pt\").input_ids\n",
        "    return untruncated_ids.shape[-1]\n",
        "\n",
        "  def max_word_count(self):\n",
        "    if self.pipe is None:\n",
        "      return 0\n",
        "    multiple = 1\n",
        "    if hasattr(self.textEncoder, \"max_embeddings_multiples\"):\n",
        "      multiple = self.textEncoder.max_embeddings_multiples\n",
        "    return multiple * (self.pipe.tokenizer.model_max_length-2)+2 #先頭と末尾の2wordを引いてから倍数をかける\n",
        "\n",
        "  # Masked Content の \"latent nothing\"を実装（未完成）\n",
        "  def create_latent_nothing(self, info, generator=None):\n",
        "    # https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py から抜粋・変更\n",
        "    value=0.0\n",
        "    device = self.pipe.device\n",
        "    dtype = self.pipe.text_encoder.dtype\n",
        "    num_channels_latents = self.pipe.unet.in_channels\n",
        "    batch_size = info.batch_size * 1 # num_images_per_prompt = 1 as default\n",
        "    shape = (batch_size, num_channels_latents, info.height // self.pipe.vae_scale_factor, info.width // self.pipe.vae_scale_factor)\n",
        "    return torch.full(shape, value, device=device, dtype=dtype).to(self.device_to)\n",
        "\n",
        "  # Masked Content の \"latent noise\"を実装\n",
        "  def create_latent_noise(self, info, generator):\n",
        "    # https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py から抜粋・変更\n",
        "    device = self.pipe.device\n",
        "    dtype = self.pipe.text_encoder.dtype\n",
        "    num_channels_latents = self.pipe.unet.in_channels\n",
        "    batch_size = info.batch_size * 1 # num_images_per_prompt = 1 as default\n",
        "    shape = (batch_size, num_channels_latents, info.height // self.pipe.vae_scale_factor, info.width // self.pipe.vae_scale_factor)\n",
        "    return torch.randn(shape, device=device, dtype=dtype, generator=generator).to(self.device_to)\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  inpaint, img2img, txt2imgの画像生成で使う初期データを決める\n",
        "  Stable Diffusionにおいてはいずれの機能も手順は同じで、初期データが違う。\n",
        "  本実装では、img2img, txt2imgはinpaint(InpaintLegacy)の特殊化としている。\n",
        "  img2img, txt2imgの方が処理が分かりやすいため先に記述。\n",
        "  \"\"\"\n",
        "  def img2img(self, info):\n",
        "    image = info.extra_param[\"image\"]\n",
        "    strength = info.extra_param[\"strength\"]\n",
        "    new_info = info.clone_light()\n",
        "\n",
        "    new_info.extra_param[\"image\"] = image\n",
        "    new_info.extra_param[\"mask_image\"] = None\n",
        "    new_info.extra_param[\"latents\"] = None\n",
        "\n",
        "    # 画像全体を初期データとする\n",
        "    init_latent = layered_diffusion.ByImage(image=image, strength=1.0)\n",
        "    # layer: 初期データに対するデノイズ指定のレイヤー。プロンプトやCFG scaleの指定はこちらで行う\n",
        "    # プロンプトのレイヤは1枚だけ\n",
        "    layer = layered_diffusion.Layer(\n",
        "      prompt=info.prompt,\n",
        "      negative_prompt=info.negative_prompt,\n",
        "      cfg_scale=info.guidance_scale,\n",
        "      strength=strength,\n",
        "    )\n",
        "    return init_latent, layer, new_info\n",
        "\n",
        "  def txt2img(self, info):\n",
        "    # latent noiseを初期データとする\n",
        "    # txt2imgではRandomlyを使ってもGUI側でのlatent noiseとほぼ同一の画像となる\n",
        "    #（inpaintでRandomlyを使うとAUTOMATIC1111版に近い画像が出ない。inpaint()での実装を参照）\n",
        "\n",
        "    new_info = info.clone_light()\n",
        "    new_info.extra_param[\"image\"] = None\n",
        "    new_info.extra_param[\"mask_image\"] = None\n",
        "    new_info.extra_param[\"latents\"] = None\n",
        "\n",
        "    # init_latent = layered_diffusion.Randomly(symmetric=False, strength=1.0)\n",
        "    init_latent = None # Layered Diffusionでの修正を反映。initなしの場合はRandomlyが使用される\n",
        "    # プロンプトのレイヤは1枚だけ\n",
        "    layer = layered_diffusion.Layer(\n",
        "      prompt=info.prompt,\n",
        "      negative_prompt=info.negative_prompt,\n",
        "      cfg_scale=info.guidance_scale,\n",
        "      strength=1.0,\n",
        "    )\n",
        "    return init_latent, layer, new_info\n",
        "\n",
        "  # inpaintのMasked Contentで \"latent noise\", \"latent nothing\" を初期値とする場合に\n",
        "  # 潜在空間上でマスクをかけた画像データを用意\n",
        "  # stable_diffusion_pipeline.py より引用・改変\n",
        "  def prepare_image_latents(self, info, g_cpu, noise_func, strength):\n",
        "    device = self.pipe.device\n",
        "    dtype = self.pipe.text_encoder.dtype\n",
        "\n",
        "    # 4. Preprocess image and mask\n",
        "    image = lpw_stable_diffusion.preprocess_image(info.extra_param[\"image\"])\n",
        "    image = image.to(device=device, dtype=dtype)\n",
        "    mask_image = lpw_stable_diffusion.preprocess_mask(info.extra_param[\"mask_image\"], self.pipe.vae_scale_factor)\n",
        "    mask_image = mask_image.to(device=device, dtype=dtype)\n",
        "\n",
        "    # 画像にVAEを適用してlatentsを生成（このとき乱数発生）\n",
        "    init_latent_dist = self.pipe.vae.encode(image).latent_dist\n",
        "    init_latents = init_latent_dist.sample(generator=g_cpu)\n",
        "    init_latents = 0.18215 * init_latents\n",
        "    init_latents = torch.cat([init_latents] * info.batch_size, dim=0)\n",
        "\n",
        "    # latent noiseを生成\n",
        "    noise_fill = noise_func(info, g_cpu)\n",
        "\n",
        "    # マスクをかける。マスク適用範囲のみ背景とノイズをアルファブレンド\n",
        "    rate = (1.0-mask_image) * strength\n",
        "    latents = ((1.0-rate) * init_latents) + (rate * noise_fill)\n",
        "    return latents\n",
        "\n",
        "  # inpaintでの設定。マスク適用の設定により処理を分岐\n",
        "  def inpaint(self, info):\n",
        "\n",
        "    # 初期ノイズの種類を設定。\n",
        "    # ノイズの種類に対してマスクを適用したものが初期latents\n",
        "    \"\"\"\n",
        "    fill: ピクセルのgray( RGB=(128,128,128) )\n",
        "    original: imageの変換後のノイズをそのまま使う。InpaintPipelineLegacyでimageを与えたときのデフォルト値\n",
        "    latent noise: 潜在空間上でのランダムノイズ。GUI側でノイズ生成\n",
        "    latent nothing: 潜在空間上でのzeros\n",
        "    mode channel: 独自実装。マスク範囲の画素の最頻値を使う。チャネルごとに最頻値を取った値をRGB値とする\n",
        "    top image: 独自実装。指定した画像をマスクで切り抜いて上(top)に上書き\n",
        "    randomly: layered diffusionのみ。 Layered Diffusion側で latent noise を生成\n",
        "    \"\"\"\n",
        "    image = info.extra_param[\"image\"]\n",
        "    mask = info.extra_param[\"mask_image\"]\n",
        "    strength = info.extra_param[\"strength\"]\n",
        "    latents_type = info.latents_type\n",
        "    new_info = info.clone_light()\n",
        "    new_info.extra_param[\"image\"] = image\n",
        "    new_info.extra_param[\"mask_image\"] = mask\n",
        "    new_info.extra_param[\"latents\"] = None\n",
        "    #print(new_info.latents_type, new_info.extra_param)\n",
        "\n",
        "    # init_latent: 初期データの指定。[Initializer] も可能で、\n",
        "    # init_latent[0] に対し、init_latent[1]から順に複数のInitializerを、それぞれ指定したマスクをかけて重ねることが可能\n",
        "\n",
        "    # init_latentのデフォルト値。imageの変換後のノイズをそのまま使う（originalに相当）\n",
        "    # strength (Denoise strength): 拡散の順過程でノイズをかける回数の割合[0.0-1.0]。\n",
        "    # 回数 = numstep * strength、回数が多いほど初期状態がよりノイズに近づき、元の画像とはより異なる画像が生成される。\n",
        "    latent_image = layered_diffusion.ByImage(image=image, strength=strength)\n",
        "    init_latent = latent_image\n",
        "    randgen = self.pipeBuilder.scheduler.generator()\n",
        "\n",
        "    # latentsの種別を取得\n",
        "    if latents_type == \"original\":\n",
        "      pass\n",
        "    elif latents_type == \"fill\":\n",
        "      pass\n",
        "    elif latents_type == \"mode channel\":\n",
        "      pass\n",
        "    elif latents_type == \"latent noise\":\n",
        "      #マスクして上書き\n",
        "      if self.using_layered_diffusion:\n",
        "        # AUTOMATIC1111版からの再現性のため、1. 画像にVAEを適用してlatentsを生成（このとき乱数発生）、2. latent noiseを生成 の順序で処理を行う。\n",
        "        #latent_noise = layered_diffusion.Randomly(symmetric=False, mask_by=mask, strength=strength)\n",
        "        latent_noise = layered_diffusion.ByLatents(latents=self.create_latent_noise(info,randgen), mask_by=mask, strength=strength)\n",
        "        init_latent = [latent_image, latent_noise]\n",
        "      else:\n",
        "        latents = self.prepare_image_latents(info, randgen, self.create_latent_noise, strength)\n",
        "        new_info.extra_param[\"latents\"] = latents\n",
        "        new_info.extra_param[\"image\"] = None # set image None to use latents on generating\n",
        "\n",
        "    elif latents_type == \"latent nothing\":\n",
        "      #マスクして上書き\n",
        "      if self.using_layered_diffusion:\n",
        "        latent_nothing = layered_diffusion.ByLatents(latents=self.create_latent_nothing(info), mask_by=mask, strength=strength)\n",
        "        init_latent = [latent_image, latent_nothing]\n",
        "      else:\n",
        "        # 画像からlatentsを生成（乱数発生）\n",
        "        latents = self.prepare_image_latents(info, randgen, self.create_latent_nothing, strength)\n",
        "        new_info.extra_param[\"latents\"] = latents\n",
        "        new_info.extra_param[\"image\"] = None # set image None to use latents on generating\n",
        "\n",
        "    elif latents_type == \"randomly\":\n",
        "      # Layered Diffusion側で latent noise を生成。AUTOMATIC1111版とは得られる画像が異なる\n",
        "      # symmetric: 対称的なノイズにするかどうか。Trueでだいたい対称的になる\n",
        "      # TODO: symmetricのチェックボックスの対応\n",
        "      random_pixel = layered_diffusion.Randomly(symmetric=False, mask_by=mask, strength=strength)\n",
        "      init_latent = [latent_image, random_pixel]\n",
        "\n",
        "    else:\n",
        "      #未指定＝デフォルト値\n",
        "      pass\n",
        "\n",
        "    # layer: 初期データに対するデノイズ指定のレイヤー。プロンプトやCFG scaleの指定はこちらで行う\n",
        "    layer = layered_diffusion.Layer(\n",
        "      prompt=info.prompt,\n",
        "      negative_prompt=info.negative_prompt,\n",
        "      cfg_scale=info.guidance_scale,\n",
        "      strength=1.0, #TODO\n",
        "      mask_by = mask,\n",
        "    )\n",
        "    #print(new_info.latents_type, new_info.extra_param)\n",
        "    return init_latent, layer, new_info\n",
        "\n",
        "\n",
        "  # 生成した画像ファイル情報を返す\n",
        "  # info.seed == -1 （シード値を自動決定）を与えた時は、自動決定されたシード値をinfo.seedにも設定する\n",
        "  # seed_index: seedに加算、batch_count内で何回目か\n",
        "  def generate_image_progressive(self, info, pipeMethod):\n",
        "    # パイプラインを切り替える\n",
        "    # TODO? : \"KarrasVe\"などPipelineとSchedulerが不可分な場合の対応\n",
        "    if \"PipelineClass\" in self.schedulerDict[info.scheduler_name]:\n",
        "      pipelineClass = self.schedulerDict[info.scheduler_name][\"PipelineClass\"]\n",
        "      if issubclass(pipelineClass, StableDiffusionPipeline) and pipelineClass != type(self.pipe):\n",
        "        self.pipe = pipelineClass(self.components)\n",
        "        self.pipeBuilder.pipe = self.pipe\n",
        "    else:\n",
        "      # 切り替えない\n",
        "      self.pipe.scheduler = self.schedulerDict[info.scheduler_name][\"scheduler\"]\n",
        "\n",
        "    # layered_diffusion側のschedulerを設定\n",
        "    sche = layered_diffusion.Scheduler()\n",
        "    sche.scheduler = self.pipe.scheduler\n",
        "    sche.have_max_timesteps = False\n",
        "    sche._rand_seed = None\n",
        "    sche._generator = None\n",
        "    self.pipeBuilder.scheduler = sche\n",
        "\n",
        "    #シードをセット\n",
        "    if(info.seed < 0):\n",
        "      #シードを得る\n",
        "      self.pipeBuilder._ResetGenerator(None)\n",
        "      info.seed = self.pipeBuilder.GetRandSeed()\n",
        "    self.pipeBuilder._ResetGenerator(info.seed)\n",
        "\n",
        "    # 設定をパイプラインに反映\n",
        "    prompt_array = [info.prompt] * info.batch_size\n",
        "    negative_prompt_array = [info.negative_prompt] * info.batch_size\n",
        "\n",
        "    if self.safety_checker == True and self.pipe.safety_checker == None:\n",
        "      self.pipe.safety_checker = self.safety_checker_obj\n",
        "    else:\n",
        "      self.pipe.safety_checker = None\n",
        "\n",
        "    # 所要時間が増える代わりにGPUメモリ使用量を抑える\n",
        "    if self.attention_slicing:\n",
        "      self.pipe.enable_attention_slicing()\n",
        "    else:\n",
        "      self.pipe.disable_attention_slicing()\n",
        "\n",
        "    if self.using_layered_diffusion:\n",
        "      # 機能に対応した初期データとレイヤ構造を得る\n",
        "      init_latent, layer, _ = pipeMethod(info)\n",
        "\n",
        "      # initialize:初期データの指定。initialize=[Initializer] も可能で、initialize[0] に対し、initialize[1]から順に複数のinitを、\n",
        "      # それぞれ指定したマスクをかけて重ねることが可能。（InitializerList.Merge()が使用される）\n",
        "      # rmm_dump: デバッグ用のレイヤごと出力\n",
        "      outImage, rmm_dump = self.pipeBuilder(\n",
        "          num_steps = info.step_count,\n",
        "          size = (info.width, info.height),\n",
        "          default_encoding = self.textEncoder,\n",
        "          rand_seed = info.seed,\n",
        "          eta = info.eta,\n",
        "          initialize = init_latent, #上記注\n",
        "          iterate = layer,\n",
        "      ) #TODO: 返ってくるのは1バッチ分だけ？\n",
        "    \n",
        "    else:\n",
        "      # infoを書き換える\n",
        "      _, _, new_info = pipeMethod(info)\n",
        "      # 画像生成\n",
        "      outImage = self.pipe.__call__(\n",
        "        prompt=[info.prompt] * info.batch_size,\n",
        "        negative_prompt=[info.negative_prompt] * info.batch_size,\n",
        "        width=info.width,\n",
        "        height=info.height,\n",
        "        num_inference_steps=info.step_count,\n",
        "        guidance_scale=info.guidance_scale,\n",
        "        eta=info.eta,\n",
        "        generator=self.pipeBuilder.scheduler.generator(),\n",
        "        max_embeddings_multiples=3,\n",
        "        callback = None,\n",
        "        is_cancelled_callback = None,\n",
        "        **new_info.extra_param # image, mask_image, latents, strength, (inpaintのみ mask_timing, mask_output)\n",
        "      ).images[0]\n",
        "    \n",
        "    # 生成データをファイルに保存    \n",
        "    timestr=time.strftime(self.timestr_format)\n",
        "    if info.batch_size > 1:\n",
        "      # 1バッチずつファイルに保存\n",
        "      filepath = os.path.join(self.output_dir, f\"batch_{timestr}_seed{info.seed}.png\")\n",
        "      grid_image = create_batch_image(outImage, info.width, info.height, info.grid_column_count)\n",
        "      info.save_image(grid_image, filepath)\n",
        "      info.save_thumbnail(grid_image, info.resize)\n",
        "    else:\n",
        "      # 1回分のファイルを保存\n",
        "      filepath = os.path.join(self.output_dir, f\"{timestr}_seed{info.seed}.png\")\n",
        "      info.save_image(outImage, filepath)\n",
        "      info.save_thumbnail(outImage, info.resize)\n",
        "      \"\"\"\n",
        "      # デバッグ出力を保存\n",
        "      rmm_filepath = os.path.join(self.output_dir, f\"{timestr}_rmm_seed{info.seed}.png\")\n",
        "      save_image(rmm_dump, rmm_filepath, \"\")\n",
        "      \"\"\"\n",
        "    \n",
        "    return info\n",
        "\n",
        "  def synchronize(self):\n",
        "    torch.cuda.synchronize(device=self.pipe.device)\n",
        "\n",
        "  def generate_grid(self, info_list, grid_info):\n",
        "    timestr=time.strftime(self.timestr_format)\n",
        "    filepath = os.path.join(self.output_dir, f\"grid_{timestr}_seed{grid_info.seed}.png\")\n",
        "    single_batch_images = [Image.open(io.BytesIO(info.imageBytes)) for info in info_list]\n",
        "    grid_image = create_batch_image(single_batch_images, grid_info.width, grid_info.height, grid_info.grid_column_count)\n",
        "    grid_info.save_image(grid_image, filepath)\n",
        "    grid_info.save_thumbnail(grid_image, grid_info.resize)\n",
        "\n",
        "    return grid_image\n",
        "\n",
        "\n",
        "# 処理モジュールのインスタンスを生成\n",
        "sharedBackEnd = BackEnd()\n"
      ],
      "metadata": {
        "id": "hPCnLM4H7SCr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 共通GUIコンポーネント\n",
        "\n",
        "# 処理する画像のアップローダ\n",
        "class ImageUploader:\n",
        "  # 入力要素・出力要素の定義を行う。実際のレイアウトはset_layout()で設定\n",
        "  def __init__(self, parent, width, height, mode):\n",
        "    self.parent = parent\n",
        "    #画像データ、PIL Imageのインスタンス\n",
        "    self.src_image = None\n",
        "    self.mode = mode\n",
        "    #ウィジェット\n",
        "    self.src_image_widget = widgets.Image(width=f\"{width}\", height=f\"{height}\")\n",
        "    self.src_upload_button = widgets.FileUpload(accept=\".png; .jpg\", multiple=False, description=\"source img\")\n",
        "    self.src_upload_button.observe(self.on_src_upload, names='value') #FileUploadはon_clickを持たないため、valueを監視してイベントハンドラを起動  \n",
        "    self.src_upload_button.layout=Layout(width=f\"{width}\")\n",
        "\n",
        "  #ファイルアップロード完了時に元画像を更新する\n",
        "  def on_src_upload(self, change):\n",
        "    data = fileUploader_load_png(new_value=change.new) #bytes\n",
        "    self.src_image = Image.open(io.BytesIO(data)).convert(self.mode)\n",
        "    self.src_image_widget.value = data\n",
        "  \n",
        "  def set_layout(self):\n",
        "    self.layout = widgets.VBox([self.src_upload_button, self.src_image_widget])\n",
        "    return self.layout\n",
        "\n",
        "class GeneratePane:\n",
        "  def __init__(self, parent):\n",
        "    self.sampler_name_list = []\n",
        "    self.is_image_generating = False # 画像生成中フラグ\n",
        "    self.generated_file_list = []\n",
        "    self.parent = parent\n",
        "    self.prompt_textarea = widgets.Textarea()\n",
        "    self.prompt_textarea.observe(self.on_prompt_update, names='value') #valueを監視してイベントハンドラを起動\n",
        "    self.wordcount_label = widgets.Label(value=f\"prompt 0/0\")\n",
        "\n",
        "    self.negative_prompt_textarea = widgets.Textarea()\n",
        "    self.negative_prompt_textarea.observe(self.on_negative_prompt_update, names='value') #valueを監視してイベントハンドラを起動\n",
        "    self.negative_wordcount_label = widgets.Label(value=f\"negative 0/0\")\n",
        "\n",
        "    self.generate_button = widgets.Button(description=\"Generate\")\n",
        "    self.generate_button.on_click(self.parent.generate)\n",
        "\n",
        "    self.interrupt_button = widgets.Button(description=\"Interrupt\", disabled=True, layout=Layout(width=\"50%\") )\n",
        "    self.stop_button = widgets.Button(description=\"Stop\", disabled=True, layout=Layout(width=\"50%\") )\n",
        "\n",
        "  # PNGInfoから得たパラメータ情報を反映させる\n",
        "  def reflectPNGInfo(self, info:GeneratedFileInfo):\n",
        "    self.prompt_textarea.value = info.prompt\n",
        "    self.negative_prompt_textarea.value = info.negative_prompt\n",
        "\n",
        "  def on_prompt_update(self, change):\n",
        "    word_count = sharedBackEnd.word_count(change.new)\n",
        "    max_word_count = sharedBackEnd.max_word_count()\n",
        "    self.wordcount_label.value = f\"prompt {word_count}/{max_word_count}\"\n",
        "\n",
        "  def on_negative_prompt_update(self, change):\n",
        "    word_count = sharedBackEnd.word_count(change.new)\n",
        "    max_word_count = sharedBackEnd.max_word_count()\n",
        "    self.negative_wordcount_label.value = f\"negative {word_count}/{max_word_count}\"\n",
        "\n",
        "  # 入力要素の定義とレイアウト設定を分離する\n",
        "  def set_layout(self):\n",
        "    #入力要素のレイアウトを設定\n",
        "    self.prompt_textarea.placeholder=\"prompt\"\n",
        "    self.prompt_textarea.layout = Layout(width=\"100%\",height=\"7em\")\n",
        "    self.negative_prompt_textarea.placeholder=\"Negative prompt\"\n",
        "    self.negative_prompt_textarea.layout = Layout(width=\"100%\",height=\"7em\", border=\"solid 0px\")\n",
        "    self.generate_button.style={\"button_color\":\"lightskyblue\"}\n",
        "    #generate_stack = widgets.Stack([generate_button, interrupt_button], selected_index=0, layout = Layout(width=\"100%\",height=\"100%\"))\n",
        "    self.generate_stack = widgets.VBox([\\\n",
        "      self.generate_button, widgets.HBox([self.interrupt_button, self.stop_button], layout = Layout(width=\"100%\",height=\"50%\")) \\\n",
        "    ])\n",
        "\n",
        "    self.layout = widgets.HBox(layout=Layout(border=\"solid 0px\"), children=[\n",
        "      # 生成ボタン類\n",
        "      widgets.VBox(layout=Layout(width=\"15%\",height=\"auto\", border=\"solid 0px\"), children=[\n",
        "        self.generate_stack,\n",
        "        self.wordcount_label,\n",
        "        self.negative_wordcount_label,\n",
        "      ]),\n",
        "      # プロンプト・ネガティブプロンプト\n",
        "      widgets.VBox(layout=Layout(width=\"100%\",height=\"100%\", border=\"solid 0px\"), children=[\n",
        "        widgets.Box(layout = Layout(width=\"100%\",height=\"100%\"), children=[\n",
        "          self.prompt_textarea,\n",
        "        ]),\n",
        "        widgets.Box(layout = Layout(width=\"100%\",height=\"100%\"), children=[\n",
        "          self.negative_prompt_textarea,\n",
        "        ]),\n",
        "      ]),\n",
        "    ])\n",
        "    return self.layout\n",
        "\n",
        "\n",
        "class SettingPane:\n",
        "  def __init__(self):\n",
        "    #生成パラメータ\n",
        "    self.sampling_step_slider = widgets.IntSlider(min=0, max=150, value=20)\n",
        "    self.sampling_method = widgets.Dropdown()\n",
        "    self.CFG_scale_slider = widgets.FloatSlider(min=0, max=25.0, value=7.0)\n",
        "    self.seed_input = widgets.IntText(value=-1)\n",
        "    #保存画像のサイズ・枚数\n",
        "    self.width_slider = widgets.IntSlider(min=8, max=2048, value=512, step=8)\n",
        "    self.height_slider = widgets.IntSlider(min=8, max=2048, value=512, step=8)\n",
        "    self.batch_size_input = widgets.BoundedIntText(value=1, min=1) # 1回の作業の生成枚数。枚数分だけGPUメモリを使用\n",
        "    self.batch_count_input = widgets.BoundedIntText(value=6, min=1) # 生成作業を何回行うか。回数分だけ処理時間はかかるが、GPUは1回分の使用量で済む\n",
        "    self.grid_column_count_input = widgets.BoundedIntText(value=3, min=1) # 画像gridの列の数\n",
        "\n",
        "  # PNGInfoから得たパラメータ情報を反映させる\n",
        "  def reflectPNGInfo(self, info:GeneratedFileInfo):\n",
        "    self.sampling_step_slider.value = info.step_count\n",
        "    self.width_slider.value = info.width\n",
        "    self.height_slider.value = info.height\n",
        "    self.CFG_scale_slider.value = info.guidance_scale\n",
        "    self.seed_input.value =  info.seed\n",
        "    # リストにない場合は反映しない\n",
        "    if info.scheduler_name in sharedBackEnd.schedulerDict.keys() and info.scheduler_name in self.sampling_method.options :\n",
        "      self.sampling_method.value = info.scheduler_name\n",
        "\n",
        "  # setupペインでのセットアップ内容を反映させる\n",
        "  def set_param(self, sampler_name_list, default_width, default_height):\n",
        "    self.sampler_name_list = sampler_name_list\n",
        "    self.sampling_method.options=sampler_name_list\n",
        "    self.sampling_method.value=sampler_name_list[0]\n",
        "    self.width_slider.value = default_width\n",
        "    self.height_slider.value = default_height\n",
        "\n",
        "  # 入力要素の定義とレイアウト設定を分離する\n",
        "  def set_layout(self):\n",
        "    self.sampling_step_slider.style={\"description_width\":\"10em\"}\n",
        "    self.sampling_step_slider.layout=Layout(width=\"90%\", border=\"solid 0px\")\n",
        "    self.sampling_step_slider.description=\"steps\"\n",
        "    self.sampling_method.style={\"description_width\":\"10em\"}\n",
        "    self.sampling_method.layout=Layout(width=\"90%\", border=\"solid 0px\")\n",
        "    self.sampling_method.description=\"method\"\n",
        "\n",
        "    self.CFG_scale_slider.style={\"description_width\":\"10em\"}\n",
        "    self.CFG_scale_slider.layout=Layout(width=\"90%\", border=\"solid 0px\")\n",
        "    self.CFG_scale_slider.description=\"CFG scale\"\n",
        "    self.seed_input.style={\"description_width\":\"10em\"}\n",
        "    self.seed_input.layout=Layout(width=\"90%\", border=\"solid 0px\")\n",
        "    self.seed_input.description=\"seed\"\n",
        "\n",
        "    self.width_slider.style={\"description_width\":\"10em\"}\n",
        "    self.width_slider.layout=Layout(width=\"90%\", border=\"solid 0px\")\n",
        "    self.width_slider.description=\"width\"\n",
        "    self.height_slider.style={\"description_width\":\"10em\"}\n",
        "    self.height_slider.layout=Layout(width=\"90%\", border=\"solid 0px\")\n",
        "    self.height_slider.description=\"height\"\n",
        "\n",
        "    self.batch_size_input.style={\"description_width\":\"10em\"}\n",
        "    self.batch_size_input.layout=Layout(width=\"90%\", border=\"solid 0px\")\n",
        "    self.batch_size_input.description=\"batch Size\"\n",
        "    self.batch_count_input.style={\"description_width\":\"10em\"}\n",
        "    self.batch_count_input.layout=Layout(width=\"90%\", border=\"solid 0px\")\n",
        "    self.batch_count_input.description=\"batch Count\"\n",
        "    self.grid_column_count_input.style={\"description_width\":\"10em\"}\n",
        "    self.grid_column_count_input.layout=Layout(width=\"90%\", border=\"solid 0px\")\n",
        "    self.grid_column_count_input.description=\"grid columns\"\n",
        "\n",
        "    # txt2imgの設定ペイン\n",
        "    self.setting_pane_content = {\n",
        "      \"sampling\":widgets.VBox([self.sampling_step_slider, self.sampling_method]),\n",
        "      \"quality params\":widgets.VBox([self.CFG_scale_slider,self.seed_input]),\n",
        "      \"image size\":widgets.VBox([\n",
        "        self.width_slider, self.height_slider,\n",
        "        self.batch_size_input, self.batch_count_input,\n",
        "        self.grid_column_count_input\n",
        "      ]),\n",
        "      }\n",
        "    self.setting_pane = widgets.VBox(layout = Layout(width=\"100%\", height=\"100%\"))\n",
        "    # tabを1個ずつ追加（tab切り替えは不使用。tabの部分をタイトル表示にのみ使用）\n",
        "    children_array = list(self.setting_pane_content.values())\n",
        "    self.setting_pane.children = [widgets.Tab([wd]) for wd in children_array]\n",
        "    for i,title in enumerate(self.setting_pane_content.keys()):\n",
        "      self.setting_pane.children[i].set_title(0, title)\n",
        "\n",
        "    self.layout = widgets.Box([self.setting_pane], layout=Layout(width=\"100%\", border=\"solid 0px\") )\n",
        "    return self.layout\n",
        "\n",
        "class OutputPane:\n",
        "  # 入力要素・出力要素の定義を行う。実際のレイアウトはset_layout()で設定\n",
        "  def __init__(self):\n",
        "    self.thumbnail_size = 64 # px\n",
        "    self.thumbnail_button_width = 16 # px\n",
        "    self.thumbnail_button_height = 64 # px\n",
        "    # 出力画像ビューワの部分\n",
        "    self.focus_image = widgets.Image(width=\"512\", height=\"512\")\n",
        "    self.focus_image_box = widgets.Box()\n",
        "    self.thumbnail_viewer = widgets.VBox()\n",
        "    self.generated_file_list = []\n",
        "    self.output = widgets.Output()\n",
        "\n",
        "    #GUIデバッグ用\n",
        "    self.viewer_debug = False\n",
        "    #self.viewer_debug = True\n",
        "    if self.viewer_debug:\n",
        "      self.viewer_debug = True\n",
        "      #string_generated_file_list = [\"thumbnail01.png\", \"thumbnail02.png\",]\n",
        "      string_generated_file_list = [\"test_image.png\",\"test_image.png\"]\n",
        "      #string_generated_file_list = []\n",
        "      for filename in string_generated_file_list:\n",
        "        # 1回分のファイルを保存\n",
        "        image = Image.open(filename)\n",
        "        resize=0.25\n",
        "        thumbnail = image.resize(size=(int(image.width*resize),int(image.height*resize)) )\n",
        "        info = GeneratedFileInfo(\n",
        "            prompt=\"\", negative_prompt=\"\", scheduler_name=\"\",\n",
        "            step_count=0, guidance_scale=0, seed=0,\n",
        "            width=image.width, height=image.height, batch_size=0, batch_count=0, grid_column_count=0\n",
        "        )\n",
        "        with io.BytesIO() as buf:\n",
        "          save_image(image, buf, \"\")\n",
        "          info.imageBytes = buf.getvalue()\n",
        "        with io.BytesIO() as buf:\n",
        "          save_image(thumbnail, buf, \"\")\n",
        "          info.thumbnailBytes = buf.getvalue()\n",
        "        self.generated_file_list.append(info)\n",
        "  \n",
        "  # 入力要素の定義とレイアウト設定を分離する\n",
        "  def set_layout(self):\n",
        "    self.focus_image_box.children = [self.focus_image]\n",
        "    self.focus_image_box.layout = Layout(width=\"520\", height=\"520\") #64x64 px thumbnail\n",
        "    self.focus_image.layout.object_fit = 'contain'\n",
        "    self.focus_image.layout.object_position = 'top'\n",
        "    self.thumbnail_viewer.layout = Layout(width=\"100\", height=\"520\") #64x64 px thumbnail\n",
        "\n",
        "    self.layout = widgets.VBox(layout=Layout(border=\"lightgray solid 1px\"), children=[\n",
        "          widgets.Label(value=\"right click to download an image or thumbnail / click a 🖼️ button to show a full image\", layout=Layout(height=\"2em\")), # notion\n",
        "          widgets.HBox([self.focus_image, self.thumbnail_viewer], layout=Layout(width=\"100%\", height=\"520\", border=\"solid 0px\") ), #生成画像\n",
        "          widgets.Box([self.output],layout=Layout(width=\"100%\", height=\"16em\", border=\"gray solid 1px\")), # output\n",
        "        ])\n",
        "    return self.layout\n",
        "\n",
        "  #\"generate\"ボタン押下時に画像生成し、1枚ずつサムネイル表示\n",
        "  def generate_progressive(self, ui_info, pipeMethod):\n",
        "    # UIと絶縁するため、ディープコピーを取る\n",
        "    info = ui_info.clone_light()\n",
        "    #extra_paramはシャローコピー\n",
        "    info.extra_param = ui_info.extra_param\n",
        "\n",
        "    self.output.clear_output()\n",
        "    with self.output:\n",
        "      #TODO: 生成中はボタンを押せないようにする\n",
        "      #TODO: implement GUI of batch_size, batch_count and grid_column_count\n",
        "      if self.viewer_debug:\n",
        "        count = len(self.generated_file_list)\n",
        "      else:\n",
        "        self.generated_file_list = []\n",
        "        count = info.batch_count\n",
        "    \n",
        "      # 先にサムネイルリストを生成\n",
        "      #batch_size == 1のときはgridも生成\n",
        "      if info.batch_size == 1:\n",
        "        thumbnail_count = count+1\n",
        "      else:\n",
        "        thumbnail_count = count\n",
        "      self.create_thumbnail_list(thumbnail_count)\n",
        "\n",
        "      # 1枚ずつ生成し、その都度サムネイルを表示\n",
        "      init_seed = info.seed\n",
        "      count_seed = info.seed\n",
        "      for i in range(count):\n",
        "        # シード値が-1（自動決定）でかつ初回の生成では、画像生成側でシード値を決める\n",
        "        if not(init_seed < 0 and i == 0):\n",
        "          # 2回目以降またはシード値固定の場合は、すでにあるシード値に加算する\n",
        "          count_seed = init_seed + i\n",
        "\n",
        "        # 反復ごとに絶縁するため、ディープコピーを取る\n",
        "        new_info = info.clone_light()\n",
        "        #extra_paramはシャローコピー\n",
        "        new_info.extra_param = info.extra_param\n",
        "\n",
        "        new_info.seed = count_seed\n",
        "        if self.viewer_debug:\n",
        "          file = self.generated_file_list[i]\n",
        "        else:\n",
        "          # 画像生成\n",
        "          sharedBackEnd.generate_image_progressive(new_info, pipeMethod)\n",
        "          self.generated_file_list.append(new_info)\n",
        "          # 画像生成時に決定したシード値を得る\n",
        "          if init_seed < 0 and i == 0:\n",
        "            count_seed = new_info.seed\n",
        "            init_seed = new_info.seed #gridに書き込むためこれも書き換えておく\n",
        "        \n",
        "        if new_info.batch_size == 1:\n",
        "          index = i+1 #children[0]はgrid\n",
        "        else:\n",
        "          index = i\n",
        "        #サムネイルを表示（画像データをセット）\n",
        "        self.set_thumbnail(index, new_info.thumbnailBytes)\n",
        "      \n",
        "    #self.output.clear_output()\n",
        "    with self.output:\n",
        "      #gridを作成\n",
        "      if info.batch_size == 1:\n",
        "        grid_info = info.clone_light()\n",
        "        grid_info.extra_param = info.extra_param\n",
        "        grid_info.seed = init_seed\n",
        "        grid = sharedBackEnd.generate_grid(self.generated_file_list, grid_info)\n",
        "        #先頭に追加\n",
        "        self.generated_file_list.insert(0, grid_info)\n",
        "        #サムネイルを表示（画像データをセット）\n",
        "        self.set_thumbnail(0, grid_info.thumbnailBytes)\n",
        "    \n",
        "    self.is_image_generating = False\n",
        "    return self.generated_file_list\n",
        "\n",
        "  #先にサムネイルリストを生成\n",
        "  def create_thumbnail_list(self, count):\n",
        "      thumbnail_widget_list = []\n",
        "      self.thumbnail_button_list = [] #クリックイベントハンドラ内でボタンに対応するインデックスを得るためのリスト\n",
        "      #空のサムネイルリストを生成\n",
        "      for i in range(count):\n",
        "        wd = self.create_viewer_progressive()\n",
        "        thumbnail_widget_list.append(wd)\n",
        "      #先にサムネイルリストをビューワに追加\n",
        "      self.thumbnail_viewer.children = thumbnail_widget_list\n",
        "\n",
        "  #サムネイルに画像データをセット\n",
        "  def set_thumbnail(self, index, thumbnailBytes):\n",
        "    self.thumbnail_viewer.children[index].children[0].value = thumbnailBytes\n",
        "\n",
        "  #サムネイルボタンのクリックイベントハンドラを生成\n",
        "  def focus_handler(self, change):\n",
        "    button = change\n",
        "    i = self.thumbnail_button_list.index(button)\n",
        "    self.focus_image.value = self.generated_file_list[i].imageBytes\n",
        "\n",
        "\n",
        "  # 空のサムネイルを追加\n",
        "  def create_viewer_progressive(self):\n",
        "    image = widgets.Image(width=self.thumbnail_size, height=self.thumbnail_size)\n",
        "    image.layout.object_fit = 'contain'\n",
        "\n",
        "    # クリックしてfocus_imageを更新するボタンを生成\n",
        "    button = widgets.Button(description=\"🖼️\")\n",
        "    button.layout = Layout(width=f\"{self.thumbnail_button_width}\", height=f\"{self.thumbnail_button_height}\")\n",
        "    button.on_click(self.focus_handler)\n",
        "    self.thumbnail_button_list.append(button)\n",
        "\n",
        "    # 画像とボタンを並べたものを1セットとしてサムネイルに追加\n",
        "    return widgets.HBox([image, button])\n"
      ],
      "metadata": {
        "id": "hN8OWOO5kkyZ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title setupタブ\n",
        "\n",
        "# モデル使用時のコンポーネント類は https://huggingface.co/fooID/barModel/\n",
        "# 下の model_index.json をデフォルト設定として参照して内部的にロードされる。ほかのモデルでも同様の仕組み\n",
        "\n",
        "class SetupUIView:\n",
        "  def __init__(self):\n",
        "    self.model_revision = {\n",
        "      # stable diffusion official\n",
        "      \"stabilityai/stable-diffusion-2-1-base\":{\"default\":\"fp16\", \"revision\":[\"main\",\"bf16\",\"fp16\"]},\n",
        "      \"stabilityai/stable-diffusion-2-1\":{\"default\":\"fp16\", \"revision\":[\"main\",\"bf16\",\"fp16\"], \"width\":768, \"height\":768},\n",
        "      #\"stabilityai/stable-diffusion-2-depth\":{\"default\":\"fp16\", \"revision\":[\"main\",\"fp16\"]},\n",
        "      \"runwayml/stable-diffusion-v1-5\":{\"default\":\"fp16\", \"revision\":[\"main\",\"bf16\",\"flax\",\"fp16\",\"onnx\"]},\n",
        "      \"naclbit/trinart_stable_diffusion_v2\":{\"default\":\"diffusers-115k\", \"revision\":[\"main\",\"diffusers-115k\",\"diffusers-95k\",\"diffusers-60k\"]},\n",
        "      \"naclbit/trinart_characters_19.2m_stable_diffusion_v1\":{\"default\":\"main\", \"revision\":[\"main\"]},\n",
        "      #\"\":{\"default\":\"main\", \"revision\":[\"main\"]},\n",
        "    }\n",
        "    self.device_to_list=[\"cuda\", \"cpu\"]\n",
        "    self.width=512\n",
        "    self.height=512\n",
        "\n",
        "    self.model_select = widgets.Dropdown(options=list(self.model_revision.keys()), value=list(self.model_revision.keys())[0] )\n",
        "    self.revision_select = widgets.Dropdown(options=[])\n",
        "    self.enable_other_model_check = widgets.Checkbox(value=False)\n",
        "    self.other_model_input = widgets.Text(value=\"\")\n",
        "    self.other_revision_input = widgets.Text(value=\"main\")\n",
        "    self.enable_layered_diffusion_check = widgets.Checkbox(value=True)\n",
        "\n",
        "    #on_clickを持たないため、valueを監視してイベントハンドラを起動\n",
        "    def on_using_layered_diffusion_check(change):\n",
        "      sharedBackEnd.using_layered_diffusion = change.new\n",
        "    self.enable_layered_diffusion_check.observe(on_using_layered_diffusion_check, names='value')\n",
        "\n",
        "    #modelに応じてrevisionリストを変える\n",
        "    def update_revision(change):\n",
        "      model = change['new']\n",
        "      self.revision_select.options = self.model_revision[model][\"revision\"]\n",
        "      self.revision_select.value = self.model_revision[model][\"default\"]\n",
        "    self.model_select.observe(update_revision, 'value')\n",
        "    #revision_selectの初期値を設定\n",
        "    update_revision({'new':self.model_select.value})\n",
        "\n",
        "    self.device_to_select = widgets.Dropdown(options=self.device_to_list, value=self.device_to_list[0])\n",
        "    self.enable_attention_slicing_check = widgets.Checkbox(value=False)\n",
        "    self.xformers_memory_efficient_attention_check = widgets.Checkbox(value=False)\n",
        "    self.enable_safety_checker_check = widgets.Checkbox(value=True)\n",
        "\n",
        "    #on_clickを持たないため、valueを監視してイベントハンドラを起動\n",
        "    def on_safety_checker_check(change):\n",
        "      sharedBackEnd.safety_checker = change.new    \n",
        "    self.enable_safety_checker_check.observe(on_safety_checker_check, names='value')\n",
        "\n",
        "    def on_enable_attention_slicing_check(change):\n",
        "      sharedBackEnd.attention_slicing = change.new\n",
        "    self.enable_attention_slicing_check.observe(on_enable_attention_slicing_check, names='value')\n",
        "\n",
        "    def on_xformers_memory_efficient_attention_check(change):\n",
        "      sharedBackEnd.xformers_memory_efficient_attention = change.new    \n",
        "    self.xformers_memory_efficient_attention_check.observe(on_xformers_memory_efficient_attention_check, names='value')\n",
        "\n",
        "    self.setup_button = widgets.Button(description=\"Setup\")\n",
        "    self.setup_button.on_click(self.on_setup)\n",
        "    self.output = widgets.Output()\n",
        "\n",
        "  def set_layout(self):\n",
        "    self.model_select.style={\"description_width\":\"10em\"}\n",
        "    self.model_select.layout=Layout(width=\"36em\")\n",
        "    self.model_select.description=\"preset model ID\"\n",
        "    self.revision_select.description=\"revision\"\n",
        "    self.revision_select.layout=Layout(width=\"15em\")\n",
        "    self.enable_other_model_check.style={\"description_width\":\"6em\"}\n",
        "    self.enable_other_model_check.layout=Layout(width=\"14em\")\n",
        "    self.enable_other_model_check.description=\"other model\"\n",
        "    self.other_model_input.style={\"description_width\":\"0em\"}\n",
        "    self.other_model_input.layout=Layout(width=\"36em\")\n",
        "    self.other_model_input.description=\"\"\n",
        "    self.other_revision_input.style={\"description_width\":\"4.5em\"}\n",
        "    self.other_revision_input.layout=Layout(width=\"12em\")\n",
        "    self.other_revision_input.description=\"revision\"\n",
        "    self.enable_layered_diffusion_check.description=\"use layered_diffusion\"\n",
        "\n",
        "    self.device_to_select.style={\"description_width\":\"10em\"}\n",
        "    self.device_to_select.layout=Layout(width=\"16em\")\n",
        "    self.device_to_select.description=\"device to\"\n",
        "    self.enable_attention_slicing_check.style={\"description_width\":\"10em\"}\n",
        "    self.enable_attention_slicing_check.layout=Layout(width=\"22em\")\n",
        "    self.enable_attention_slicing_check.description=\"attention slicing\"\n",
        "    self.xformers_memory_efficient_attention_check.style={\"description_width\":\"10em\"}\n",
        "    self.xformers_memory_efficient_attention_check.layout=Layout(width=\"12em\")\n",
        "    self.xformers_memory_efficient_attention_check.description=\"xformers memory efficient attention\"\n",
        "    self.enable_safety_checker_check.style={\"description_width\":\"10em\"}\n",
        "    self.enable_safety_checker_check.layout=Layout(width=\"22em\")\n",
        "    self.enable_safety_checker_check.description=\"safety checker\"\n",
        "    self.setup_button.style={\"button_color\":\"lightgreen\"}\n",
        "\n",
        "    # setupの設定ペイン\n",
        "    self.setting_pane_content = {\n",
        "      \"model\": widgets.VBox(layout=Layout(border=\"solid 0px\"), children=[\\\n",
        "        widgets.HBox(layout=Layout(border=\"solid 0px\"), children=[ \\\n",
        "          self.model_select,\n",
        "          self.revision_select,\n",
        "        ]),\n",
        "        widgets.HBox(layout=Layout(border=\"solid 0px\"), children=[ \\\n",
        "          self.enable_other_model_check,\n",
        "          self.other_model_input,\n",
        "          self.other_revision_input,\n",
        "        ]),\n",
        "        widgets.HBox([self.enable_layered_diffusion_check]),\n",
        "      ]),\n",
        "      \"device\":widgets.VBox([\n",
        "        self.device_to_select,\n",
        "        widgets.HBox([\n",
        "          self.enable_attention_slicing_check,\n",
        "          #self.xformers_memory_efficient_attention_check,\n",
        "          self.enable_safety_checker_check,\n",
        "        ]),\n",
        "      ]),\n",
        "    }\n",
        "    self.setting_pane = widgets.VBox(layout = Layout(width=\"62em\", height=\"100%\"))\n",
        "    # tabを1個ずつ追加（tab切り替えは不使用。tabの部分をタイトル表示にのみ使用）\n",
        "    children_array = list(self.setting_pane_content.values())\n",
        "    self.setting_pane.children = [widgets.Tab([wd]) for wd in children_array]\n",
        "    for i,title in enumerate(self.setting_pane_content.keys()):\n",
        "      self.setting_pane.children[i].set_title(0, title)\n",
        "\n",
        "    self.layout = widgets.VBox(layout=Layout(width=\"100%\", border=\"solid 0px\"), children=[\n",
        "      self.setting_pane,\n",
        "      self.setup_button,\n",
        "      widgets.Box([self.output],layout=Layout(width=\"100%\", height=\"20em\", border=\"gray solid 1px\"))\n",
        "    ])\n",
        "\n",
        "    return self.layout\n",
        "\n",
        "  def on_setup(self, change):\n",
        "    # model, revisionをチェック\n",
        "    if self.enable_other_model_check.value == True:\n",
        "      model = self.other_model_input.value\n",
        "      revision = self.other_revision_input.value\n",
        "    else:\n",
        "      model = self.model_select.value\n",
        "      revision = self.revision_select.value\n",
        "    \n",
        "    # デフォルトwidth, heightを変更\n",
        "    if \"width\" in self.model_revision[self.model_select.value]:\n",
        "      self.width = self.model_revision[self.model_select.value][\"width\"]\n",
        "    if \"height\" in self.model_revision[self.model_select.value]:\n",
        "      self.height = self.model_revision[self.model_select.value][\"height\"]\n",
        "    # 画像生成モジュールをセットアップ\n",
        "    self.output.clear_output()\n",
        "    with self.output:\n",
        "      sharedBackEnd.setup(\n",
        "        model=model, revision=revision, device_to=self.device_to_select.value, \n",
        "        output_dir=\"/content/output\", default_width=self.width, default_height=self.height,\n",
        "        attention_slicing=self.enable_attention_slicing_check.value,\n",
        "        xformers_memory_efficient_attention=self.xformers_memory_efficient_attention_check.value,\n",
        "        safety_checker=self.enable_safety_checker_check.value,\n",
        "        using_layered_diffusion=self.enable_layered_diffusion_check.value,\n",
        "      )\n",
        "\n",
        "# ペインのインスタンスを生成\n",
        "setupPane = SetupUIView()\n",
        "\n"
      ],
      "metadata": {
        "id": "NdepnHDV7Nlf",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title txt2imgタブ\n",
        "\n",
        "class Txt2imgPaneView:\n",
        "  # 入力要素・出力要素の定義を行う。実際のレイアウトはset_layout()で設定\n",
        "  def __init__(self):\n",
        "    self.generatePane = GeneratePane(self)\n",
        "    self.settingPane = SettingPane()\n",
        "    self.outputPane = OutputPane()\n",
        "\n",
        "  # PNGInfoから得たパラメータ情報を反映させる\n",
        "  def reflectPNGInfo(self, info):\n",
        "    self.generatePane.reflectPNGInfo(info)\n",
        "    self.settingPane.reflectPNGInfo(info)\n",
        "\n",
        "  # setupペインでのセットアップ内容を反映させる\n",
        "  def set_param(self, sampler_name_list, default_width, default_height):\n",
        "    self.settingPane.set_param(sampler_name_list, default_width, default_height)\n",
        "\n",
        "  def generate(self, change):\n",
        "    info = GeneratedFileInfo(\n",
        "      prompt = self.generatePane.prompt_textarea.value,\n",
        "      negative_prompt = self.generatePane.negative_prompt_textarea.value,\n",
        "      scheduler_name = self.settingPane.sampling_method.value,\n",
        "      step_count = self.settingPane.sampling_step_slider.value,\n",
        "      guidance_scale = self.settingPane.CFG_scale_slider.value,\n",
        "      seed = self.settingPane.seed_input.value,\n",
        "      width = self.settingPane.width_slider.value,\n",
        "      height = self.settingPane.height_slider.value,\n",
        "      batch_size = self.settingPane.batch_size_input.value,\n",
        "      batch_count = self.settingPane.batch_count_input.value,\n",
        "      grid_column_count = self.settingPane.grid_column_count_input.value,\n",
        "      eta=0.0,\n",
        "      resize=0.25\n",
        "    )\n",
        "    self.outputPane.generate_progressive(info, sharedBackEnd.txt2img)\n",
        "\n",
        "\n",
        "\n",
        "  # 入力要素の定義とレイアウト設定を分離する\n",
        "  # 全体のレイアウトを設定\n",
        "  def set_layout(self):\n",
        "    self.layout = \\\n",
        "    widgets.VBox(layout=Layout(width=\"100%\", border=\"solid 0px\"), children=[\n",
        "      self.generatePane.set_layout(),\n",
        "      # 設定／生成画像\n",
        "      widgets.HBox(layout=Layout(border=\"solid 0px\"), children=[\n",
        "        widgets.Box([self.settingPane.set_layout()], layout=Layout(width=\"45%\")),\n",
        "        widgets.Box([self.outputPane.set_layout()], layout=Layout(width=\"55%\")),\n",
        "      ]),\n",
        "    ])\n",
        "    return self.layout\n",
        "\n",
        "\n",
        "# txt2imgペインのインスタンスを生成\n",
        "txt2imgPane = Txt2imgPaneView()\n"
      ],
      "metadata": {
        "id": "JMFHcTg2OayW",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title img2imgタブ\n",
        "\n",
        "class Img2imgPane:\n",
        "  # 入力要素・出力要素の定義を行う。実際のレイアウトはset_layout()で設定\n",
        "  def __init__(self, parent):\n",
        "    self.parent = parent\n",
        "    #画像データ\n",
        "    self.src_image = None\n",
        "    #ウィジェット\n",
        "    self.src_image_widget = widgets.Image(width=\"120\", height=\"120\")\n",
        "    self.denoise_strength_slider = widgets.FloatSlider(description=\"Denoising strength\", min=0, max=1.0, value=0.75)\n",
        "    self.src_upload_button = widgets.FileUpload(accept=\".png; .jpg\", multiple=False, description=\"source img\")\n",
        "    self.src_upload_button.observe(self.on_src_upload, names='value') #FileUploadはon_clickを持たないため、valueを監視してイベントハンドラを起動\n",
        "\n",
        "  # PNGInfoから得たパラメータ情報を反映させる\n",
        "  def reflectPNGInfo(self, info:GeneratedFileInfo):\n",
        "    if 'strength' in info.extra_param:\n",
        "      self.denoise_strength_slider.value = info.extra_param['strength']\n",
        "\n",
        "  # txt2imgペインのレイアウトを設定\n",
        "  # 入力要素の定義とレイアウト設定を分離する\n",
        "  def set_layout(self):\n",
        "    content = widgets.VBox(layout=Layout(width=\"100%\"), children=[\n",
        "      widgets.HBox(layout=Layout(width=\"100%\", border=\"solid 0px\"), children=[\n",
        "        widgets.VBox([self.src_upload_button, self.src_image_widget]),\n",
        "      ]),\n",
        "      widgets.HBox(layout=Layout(width=\"100%\", border=\"solid 0px\"), children=[\n",
        "        self.denoise_strength_slider,        \n",
        "      ])\n",
        "    ])\n",
        "\n",
        "    self.denoise_strength_slider.style={\"description_width\":\"10em\"}\n",
        "    self.denoise_strength_slider.layout=Layout(width=\"20em\", border=\"solid 0px\")\n",
        "    self.src_upload_button.layout=Layout(width=\"100\")\n",
        "\n",
        "    tab = widgets.Tab([content])\n",
        "    tab.set_title(0, \"img2img\")\n",
        "\n",
        "    # 全体のレイアウトを設定\n",
        "    self.layout = \\\n",
        "    widgets.Box(layout=Layout(width=\"100%\", border=\"solid 0px\"), children=[\n",
        "      tab,\n",
        "    ])\n",
        "\n",
        "    return self.layout\n",
        "\n",
        "  #ファイルアップロード完了時に元画像を更新する\n",
        "  def on_src_upload(self, change):\n",
        "    data = fileUploader_load_png(new_value=change.new) #bytes\n",
        "    self.src_image = Image.open(io.BytesIO(data)).convert(\"RGB\")\n",
        "    self.src_image_widget.value = data\n",
        "    \n",
        "class Img2imgPaneView:\n",
        "  # 入力要素・出力要素の定義を行う。実際のレイアウトはset_layout()で設定\n",
        "  def __init__(self):\n",
        "    self.generatePane = GeneratePane(self)\n",
        "    self.img2imgPane = Img2imgPane(self)\n",
        "    self.settingPane = SettingPane()\n",
        "    self.outputPane = OutputPane()\n",
        "\n",
        "  # PNGInfoから得たパラメータ情報を反映させる\n",
        "  def reflectPNGInfo(self, info):\n",
        "    self.generatePane.reflectPNGInfo(info)\n",
        "    self.settingPane.reflectPNGInfo(info)\n",
        "    self.img2imgPane.reflectPNGInfo(info)\n",
        "\n",
        "\n",
        "  # setupペインでのセットアップ内容を反映させる\n",
        "  def set_param(self, sampler_name_list, default_width, default_height):\n",
        "    self.settingPane.set_param(sampler_name_list, default_width, default_height)\n",
        "\n",
        "  def generate(self, change):\n",
        "    info = GeneratedFileInfo(\n",
        "      prompt = self.generatePane.prompt_textarea.value,\n",
        "      negative_prompt = self.generatePane.negative_prompt_textarea.value,\n",
        "      scheduler_name = self.settingPane.sampling_method.value,\n",
        "      step_count = self.settingPane.sampling_step_slider.value,\n",
        "      guidance_scale = self.settingPane.CFG_scale_slider.value,\n",
        "      seed = self.settingPane.seed_input.value,\n",
        "      width = self.settingPane.width_slider.value,\n",
        "      height = self.settingPane.height_slider.value,\n",
        "      batch_size = self.settingPane.batch_size_input.value,\n",
        "      batch_count = self.settingPane.batch_count_input.value,\n",
        "      grid_column_count = self.settingPane.grid_column_count_input.value,\n",
        "      eta=0.0,\n",
        "      resize=0.25,\n",
        "      extra_param = {\n",
        "        \"strength\": self.img2imgPane.denoise_strength_slider.value,\n",
        "        \"image\": self.img2imgPane.src_image,\n",
        "      }\n",
        "    )\n",
        "    # 画像を1枚ずつ生成\n",
        "    self.outputPane.generate_progressive(info, sharedBackEnd.img2img)\n",
        "\n",
        "\n",
        "\n",
        "  # 入力要素の定義とレイアウト設定を分離する\n",
        "  # 全体のレイアウトを設定\n",
        "  def set_layout(self):\n",
        "    self.layout = \\\n",
        "    widgets.VBox(layout=Layout(width=\"100%\", border=\"solid 0px\"), children=[\n",
        "      self.generatePane.set_layout(),\n",
        "      # 設定／生成画像\n",
        "      widgets.HBox(layout=Layout(width=\"100%\", border=\"solid 0px\"), children=[\n",
        "        widgets.VBox(layout=Layout(width=\"45%\", border=\"solid 0px\"), children=[\n",
        "          self.img2imgPane.set_layout(),\n",
        "          self.settingPane.set_layout(),\n",
        "        ]),\n",
        "        widgets.Box([self.outputPane.set_layout()], layout=Layout(width=\"50%\", border=\"solid 0px\"))\n",
        "      ]),\n",
        "    ])\n",
        "    return self.layout\n",
        "\n",
        "\n",
        "\n",
        "#Inpaintペインのインスタンスを生成\n",
        "img2imgPane = Img2imgPaneView()\n"
      ],
      "metadata": {
        "id": "b2RW4vpYgu6_",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Inpaintタブ\n",
        "\n",
        "\n",
        "class InpaintPane:\n",
        "  # 入力要素・出力要素の定義を行う。実際のレイアウトはset_layout()で設定\n",
        "  def __init__(self, parent):\n",
        "    self.parent = parent\n",
        "    self.model_sample_size = 512\n",
        "    #画像データ\n",
        "    self.src_image = None\n",
        "    self.mask_image = None\n",
        "    self.top_image = None\n",
        "    self.inpaint_image = None\n",
        "    #ウィジェット\n",
        "    self.src_image_widget = widgets.Image(width=\"100\", height=\"100\")\n",
        "    self.mask_image_widget = widgets.Image(width=\"100\", height=\"100\", layout=Layout(border=\"dotted 1px skyblue\") )\n",
        "    self.top_image_widget = widgets.Image(width=\"100\", height=\"100\")\n",
        "    self.overlay_widget = widgets.Image(width=\"120\", height=\"120\")\n",
        "    self.mask_switch = widgets.RadioButtons(description=\"Inpaint areas\", value=\"white\", options=[\"black\", \"white\"])\n",
        "    self.mask_switch.observe(self.on_mask_switched, names='value') #valueを監視してイベントハンドラを起動\n",
        "    self.masked_content_select = widgets.Dropdown(description=\"Masked content\", options=[\"fill\", \"original\", \"mode channel\", \"latent noise\", \"randomly\", \"top image\"])\n",
        "    self.masked_content_select.observe(self.on_MaskedContent_upload, names='value') #valueを監視してイベントハンドラを起動\n",
        "    self.denoise_strength_slider = widgets.FloatSlider(description=\"Denoising strength\", min=0, max=1.0, value=0.75)\n",
        "    self.src_upload_button = widgets.FileUpload(accept=\".png; .jpg\", multiple=False, description=\"back img\")\n",
        "    self.src_upload_button.observe(self.on_src_upload, names='value') #FileUploadはon_clickを持たないため、valueを監視してイベントハンドラを起動\n",
        "    self.mask_upload_button = widgets.FileUpload(accept=\".png; .jpg\", multiple=False, description=\"mask\")\n",
        "    self.mask_upload_button.observe(self.on_mask_upload, names='value') #valueを監視してイベントハンドラを起動\n",
        "    self.top_upload_button = widgets.FileUpload(accept=\".png; .jpg\", multiple=False, description=\"top img\")\n",
        "    self.top_upload_button.observe(self.on_top_upload, names='value') #valueを監視してイベントハンドラを起動\n",
        "    self.mask_timing_select = widgets.Dropdown(description=\"Mask timing\", options=[\"last\", \"first\", \"none\"])\n",
        "    self.enable_mask_output_check = widgets.Checkbox(value=True, description=\"Mask output\")\n",
        "\n",
        "  def set_param(self, using_layered_diffusion):\n",
        "    self.using_layered_diffusion = using_layered_diffusion\n",
        "    #TODO: settingペイン側で\"use layered_diffusion\"を切り替えた時にdisableを反映させる（notifyの仕組みが必要）\n",
        "    if using_layered_diffusion == True:\n",
        "      pass\n",
        "      #self.mask_timing_select.disable = True\n",
        "      #self.enable_mask_output_check.disable = True\n",
        "    else:\n",
        "      # LPW pipelineを使う場合は、randomlyは使用不可\n",
        "      self.masked_content_select.options=[\"fill\", \"original\", \"mode channel\", \"latent noise\", \"latent nothing\", \"top image\"]\n",
        "      #self.mask_timing_select.disable = False\n",
        "      #self.enable_mask_output_check.disable = False\n",
        "\n",
        "  # PNGInfoから得たパラメータ情報を反映させる\n",
        "  def reflectPNGInfo(self, info:GeneratedFileInfo):\n",
        "    if (info.latents_type is not None) and (info.latents_type in self.masked_content_select.options):\n",
        "      self.masked_content_select.value = info.latents_type\n",
        "\n",
        "    if 'strength' in info.extra_param:\n",
        "      self.denoise_strength_slider.value = info.extra_param['strength']\n",
        "    if 'mask_timing' in info.extra_param:\n",
        "      self.mask_timing_select.value = info.extra_param['mask_timing']\n",
        "    if 'mask_output' in info.extra_param:\n",
        "      self.enable_mask_output_check.value = info.extra_param['mask_output']\n",
        "\n",
        "  # txt2imgペインのレイアウトを設定\n",
        "  # 入力要素の定義とレイアウト設定を分離する\n",
        "  def set_layout(self):\n",
        "    inpaint_content = widgets.VBox(layout=Layout(width=\"100%\"), children=[\n",
        "      widgets.HBox(layout=Layout(width=\"100%\", border=\"solid 0px\"), children=[\n",
        "        widgets.VBox([self.src_upload_button, self.src_image_widget]),\n",
        "        widgets.VBox([self.mask_upload_button, self.mask_image_widget]),\n",
        "        widgets.VBox([self.top_upload_button, self.top_image_widget]),\n",
        "      ]),\n",
        "      widgets.HBox(layout=Layout(width=\"100%\", border=\"solid 0px\"), children=[\n",
        "        self.overlay_widget,\n",
        "        widgets.HBox(layout=Layout(width=\"100%\", border=\"solid 0px\"), children=[\n",
        "          widgets.VBox(layout=Layout(width=\"100%\", border=\"solid 0px\"), children=[\n",
        "            self.mask_switch,\n",
        "            self.masked_content_select,\n",
        "            self.denoise_strength_slider,\n",
        "          ]),\n",
        "          widgets.VBox(layout=Layout(width=\"100%\", border=\"solid 0px\"), children=[\n",
        "            widgets.Label(value=\"LPW Pipeline setting:\"),\n",
        "            self.mask_timing_select,\n",
        "            self.enable_mask_output_check,\n",
        "          ]),\n",
        "        ])\n",
        "      ])\n",
        "    ])\n",
        "\n",
        "    self.mask_switch.layout.display=\"flex\"\n",
        "    self.mask_switch.style={\"description_width\":\"10em\"}\n",
        "    self.masked_content_select.style={\"description_width\":\"10em\"}\n",
        "    self.masked_content_select.layout=Layout(width=\"20em\", border=\"solid 0px\")\n",
        "    self.denoise_strength_slider.style={\"description_width\":\"10em\"}\n",
        "    self.denoise_strength_slider.layout=Layout(width=\"95%\", border=\"solid 0px\")\n",
        "    self.src_upload_button.layout=Layout(width=\"100\")\n",
        "    self.mask_upload_button.layout=Layout(width=\"100\")\n",
        "    self.top_upload_button.layout=Layout(width=\"100\")\n",
        "    self.mask_timing_select.layout=Layout(width=\"12em\", border=\"solid 0px\")\n",
        "    #self.enable_mask_output_check.style={\"description_width\":\"6em\"}\n",
        "\n",
        "    inpaint_tab = widgets.Tab([inpaint_content])\n",
        "    inpaint_tab.set_title(0, \"inpaint\")\n",
        "\n",
        "    # 全体のレイアウトを設定\n",
        "    self.layout = \\\n",
        "    widgets.Box(layout=Layout(width=\"100%\", border=\"solid 0px\"), children=[\n",
        "      inpaint_tab,\n",
        "    ])   \n",
        "\n",
        "    return self.layout\n",
        "\n",
        "  #ファイルアップロード完了時にマスクを更新する\n",
        "  def on_mask_upload(self, change):\n",
        "    data = fileUploader_load_png(new_value=change.new) #bytes\n",
        "    self.mask_image_widget.value = data\n",
        "    self.on_mask_switched(None)\n",
        "    self.overlay_mask(self.masked_content_select.value)\n",
        "\n",
        "  #ファイルアップロード完了時にマスクを更新する\n",
        "  def on_mask_switched(self, change):\n",
        "    if self.mask_image_widget.value == None:\n",
        "      return #何もしない\n",
        "    \n",
        "    mask = Image.open(io.BytesIO(self.mask_image_widget.value)).convert(\"RGB\")\n",
        "    if(self.mask_switch.value == \"black\"):\n",
        "      #マスクを反転する\n",
        "      self.mask_image = ImageChops.invert(mask)\n",
        "    else:\n",
        "      self.mask_image = mask\n",
        "    self.overlay_mask(self.masked_content_select.value)\n",
        "\n",
        "  #ファイルアップロード完了時に元画像を更新する\n",
        "  def on_src_upload(self, change):\n",
        "    data = fileUploader_load_png(new_value=change.new) #bytes\n",
        "    self.src_image = Image.open(io.BytesIO(data)).convert(\"RGB\")\n",
        "    self.src_image_widget.value = data\n",
        "    self.overlay_mask(self.masked_content_select.value)\n",
        "\n",
        "  #ファイルアップロード完了時に元画像を更新する\n",
        "  def on_top_upload(self, change):\n",
        "    data = fileUploader_load_png(new_value=change.new) #bytes\n",
        "    self.top_image = Image.open(io.BytesIO(data)).convert(\"RGB\")\n",
        "    self.top_image_widget.value = data\n",
        "    self.overlay_mask(self.masked_content_select.value)\n",
        "\n",
        "  #ファイルアップロード完了時に元画像を更新する\n",
        "  def on_MaskedContent_upload(self, change):\n",
        "    self.overlay_mask(change.new)    \n",
        "\n",
        "  # 元画像にマスクを重ねて表示\n",
        "  def overlay_mask(self, latents_type):\n",
        "    if self.src_image == None or self.mask_image == None:\n",
        "      return #何もしない\n",
        "\n",
        "    #マスクを元画像に重ねて表示\n",
        "    self.inpaint_image = self.mask_fill_image(latents_type)\n",
        "\n",
        "    #表示用の画像データをバッファに出力\n",
        "    with io.BytesIO() as buf:\n",
        "      if not (latents_type == \"fill\" or latents_type == \"original\" or latents_type == \"mode channel\" or latents_type == \"top image\"):\n",
        "        # マスクを白抜きで表示\n",
        "        image = self.src_image.copy()\n",
        "        mask = self.mask_image.convert(\"L\")\n",
        "        image.paste(self.mask_image, mask=mask)\n",
        "        image.save(buf, format=\"png\")\n",
        "      else:\n",
        "        self.inpaint_image.save(buf, format=\"png\")\n",
        "      # 表示用の画像データをウィジェットに設定\n",
        "      self.overlay_widget.value = buf.getvalue()\n",
        "\n",
        "  # 元画像をマスクで切り抜いて塗りつぶす\n",
        "  def mask_fill_image(self, latents_type):\n",
        "    image = self.src_image.copy()\n",
        "    mask = self.mask_image.convert(\"L\")\n",
        "    fill = None\n",
        "    \n",
        "    if latents_type == \"fill\":\n",
        "      fill = Image.new(mode=\"RGB\", size=(self.src_image.width, self.src_image.height), color=\"gray\")\n",
        "    if latents_type == \"top image\" and self.top_image != None:\n",
        "      fill = self.top_image\n",
        "    elif latents_type == \"mode channel\":\n",
        "      # imageのマスク範囲におけるチャネルごとの最頻値を使う\n",
        "      histo = self.src_image.histogram(mask=mask)\n",
        "      ch_mode_index = [ max(rng, key=histo.__getitem__) for rng in [range(0,256), range(256,512), range(512,768)] ] #インデックスが画素値に相当\n",
        "      color = (ch_mode_index[0], ch_mode_index[1]-256, ch_mode_index[2]-512) #インデックスのオフセットを引く\n",
        "      #print(\"ch_mode_index\", ch_mode_index, \"color\", color)\n",
        "      fill = Image.new(mode=\"RGB\", size=(self.src_image.width, self.src_image.height), color=color)\n",
        "    elif latents_type == \"original\":\n",
        "      # 何もしない\n",
        "      pass\n",
        "    else:\n",
        "      # 何もしない\n",
        "      pass\n",
        "\n",
        "    # マスクをかける画像がなければ、元の画像（背景）を返す\n",
        "    if fill == None:\n",
        "      return self.src_image\n",
        "    else:\n",
        "      # imageにマスクをかけて貼り付け\n",
        "      # TODO: Mask Blurを実装\n",
        "      image.paste(fill, mask=mask)\n",
        "      return image\n",
        "\n",
        "    \n",
        "class InpaintPaneView:\n",
        "  # 入力要素・出力要素の定義を行う。実際のレイアウトはset_layout()で設定\n",
        "  def __init__(self):\n",
        "    self.generatePane = GeneratePane(self)\n",
        "    self.inpaintPane = InpaintPane(self)\n",
        "    self.settingPane = SettingPane()\n",
        "    self.outputPane = OutputPane()\n",
        "\n",
        "  # PNGInfoから得たパラメータ情報を反映させる\n",
        "  def reflectPNGInfo(self, info):\n",
        "    self.generatePane.reflectPNGInfo(info)\n",
        "    self.settingPane.reflectPNGInfo(info)\n",
        "    self.inpaintPane.reflectPNGInfo(info)\n",
        "\n",
        "  # setupペインでのセットアップ内容を反映させる\n",
        "  def set_param(self, sampler_name_list, default_width, default_height):\n",
        "    self.settingPane.set_param(sampler_name_list, default_width, default_height)\n",
        "    self.inpaintPane.set_param(sharedBackEnd.using_layered_diffusion)\n",
        "\n",
        "  def generate(self, change):\n",
        "    info = GeneratedFileInfo(\n",
        "      prompt = self.generatePane.prompt_textarea.value,\n",
        "      negative_prompt = self.generatePane.negative_prompt_textarea.value,\n",
        "      scheduler_name = self.settingPane.sampling_method.value,\n",
        "      step_count = self.settingPane.sampling_step_slider.value,\n",
        "      guidance_scale = self.settingPane.CFG_scale_slider.value,\n",
        "      seed = self.settingPane.seed_input.value,\n",
        "      width = self.settingPane.width_slider.value,\n",
        "      height = self.settingPane.height_slider.value,\n",
        "      batch_size = self.settingPane.batch_size_input.value,\n",
        "      batch_count = self.settingPane.batch_count_input.value,\n",
        "      grid_column_count = self.settingPane.grid_column_count_input.value,\n",
        "      eta=0.0,\n",
        "      resize=0.25,\n",
        "      latents_type = self.inpaintPane.masked_content_select.value,\n",
        "      extra_param = {\n",
        "        \"strength\": self.inpaintPane.denoise_strength_slider.value,\n",
        "        \"image\": self.inpaintPane.inpaint_image,\n",
        "        \"mask_image\": self.inpaintPane.mask_image,\n",
        "        \"mask_timing\": self.inpaintPane.mask_timing_select.value,\n",
        "        \"mask_output\": self.inpaintPane.enable_mask_output_check.value,\n",
        "      }\n",
        "    )\n",
        "    # 画像を1枚ずつ生成\n",
        "    self.outputPane.generate_progressive(info, sharedBackEnd.inpaint)\n",
        "\n",
        "\n",
        "\n",
        "  # 入力要素の定義とレイアウト設定を分離する\n",
        "  # 全体のレイアウトを設定\n",
        "  def set_layout(self):\n",
        "    self.layout = \\\n",
        "    widgets.VBox(layout=Layout(width=\"100%\", border=\"solid 0px\"), children=[\n",
        "      self.generatePane.set_layout(),\n",
        "      # 設定／生成画像\n",
        "      widgets.HBox(layout=Layout(width=\"100%\", border=\"solid 0px\"), children=[\n",
        "        widgets.VBox(layout=Layout(width=\"45%\", border=\"solid 0px\"), children=[\n",
        "          self.inpaintPane.set_layout(),\n",
        "          self.settingPane.set_layout(),\n",
        "        ]),\n",
        "        widgets.Box([self.outputPane.set_layout()], layout=Layout(width=\"50%\", border=\"solid 0px\"))\n",
        "      ]),\n",
        "    ])\n",
        "    return self.layout\n",
        "\n",
        "\n",
        "\n",
        "#Inpaintペインのインスタンスを生成\n",
        "inpaintPane = InpaintPaneView()\n",
        "\n"
      ],
      "metadata": {
        "id": "2-bK_24DXEn6",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title PNGInfoタブ\n",
        "\n",
        "# 実際のレイアウトは別途行う\n",
        "class PnginfoPaneView:\n",
        "  def __init__(self, txt2imgPane, img2imgPane, inpaintPane):\n",
        "    self.txt2imgPane = txt2imgPane\n",
        "    self.img2imgPane = img2imgPane\n",
        "    self.inpaintPane = inpaintPane\n",
        "    self.param_dict = {}\n",
        "    self.info = None #GeneratedFileInfo\n",
        "\n",
        "    self.pnginfo_prompt_textarea = widgets.Textarea(placeholder=\"prompt\", disabled=True, layout = Layout(width=\"100%\",height=\"15em\"))\n",
        "    \n",
        "    self.pnginfo_upload_button = widgets.FileUpload(accept=\".png; .jpg\", multiple=False, description=\"upload an image\")\n",
        "    self.pnginfo_upload_button.observe(self.on_pnginfo_upload, names='value') #FileUploadはon_clickを持たないため、valueを監視してイベントハンドラを起動\n",
        "    \n",
        "    self.pnginfo_upload_image = widgets.Image(width=\"512\", height=\"512\")\n",
        "    \n",
        "    self.send_to_txt2img_button = widgets.Button(description=\"send to txt2img\",layout = Layout(width=\"auto\") )\n",
        "    self.send_to_txt2img_button.on_click(self.on_send_to_txt2img)\n",
        "\n",
        "    self.send_to_img2img_button = widgets.Button(description=\"send to img2img\",layout = Layout(width=\"auto\") )\n",
        "    self.send_to_img2img_button.on_click(self.on_send_to_img2img)\n",
        "\n",
        "    self.send_to_inpaint_button = widgets.Button(description=\"send to inpaint\",layout = Layout(width=\"auto\") )\n",
        "    self.send_to_inpaint_button.on_click(self.on_send_to_inpaint)\n",
        "\n",
        "    self.thumbnail_image = widgets.Image(width=\"64\", height=\"64\")\n",
        "\n",
        "    self.enable_edit_check = widgets.Checkbox(value=False, description=\"enable edit\")\n",
        "    self.enable_edit_check.observe(self.on_enable_edit_check, names=\"value\")\n",
        "\n",
        "    self.edit_save_button = widgets.Button(description=\"save image\",layout = Layout(width=\"auto\") )\n",
        "    self.edit_save_button.on_click(self.on_edit_save)\n",
        "    self.edit_save_thumbnail_button = widgets.Button(description=\"save thumbnail\",layout = Layout(width=\"auto\") )\n",
        "    self.edit_save_thumbnail_button.on_click(self.on_edit_save_thumbnail)\n",
        "    \n",
        "  def set_layout(self):\n",
        "    # PNG Infoのペイン\n",
        "    self.layout = \\\n",
        "    widgets.HBox(layout=Layout(width=\"100%\", height=\"100%\"), children=[\n",
        "      # 画像のアップロード\n",
        "      widgets.VBox(layout=Layout(width=\"540\", height=\"100%\"), children=[\n",
        "        self.pnginfo_upload_button,\n",
        "         widgets.HBox([self.pnginfo_upload_image], layout=Layout(width=\"520\", height=\"520\")),\n",
        "      ] ),\n",
        "      # 画像の設定パラメータ表示、SendToボタン\n",
        "      widgets.VBox(layout=Layout(width=\"60%\", height=\"100%\"), children=[\n",
        "        widgets.HBox([self.pnginfo_prompt_textarea], layout=Layout(width=\"100%\", height=\"100%\")),\n",
        "        widgets.HBox( [\n",
        "          self.send_to_txt2img_button,\n",
        "          self.send_to_img2img_button,\n",
        "          self.send_to_inpaint_button,\n",
        "          widgets.VBox([\n",
        "            self.enable_edit_check,\n",
        "            widgets.HBox( [self.edit_save_button, self.edit_save_thumbnail_button,]),\n",
        "          ]),\n",
        "        ]),\n",
        "        widgets.HBox([\n",
        "          self.thumbnail_image,\n",
        "        ]),\n",
        "      ]),\n",
        "    ])\n",
        "    return self.layout\n",
        "\n",
        "  #ファイルアップロード完了時に画像とパラメータ表示を更新する\n",
        "  def on_pnginfo_upload(self, change):\n",
        "    (data, parameter_text) = update_pnginfo(new_value=change.new)\n",
        "    image = Image.open(io.BytesIO(data))\n",
        "    self.info = GeneratedFileInfo.from_parameter_text(parameter_text)\n",
        "    self.info.imageBytes = data\n",
        "    self.pnginfo_upload_image.value = data\n",
        "    self.pnginfo_upload_image.width = min(512, image.width)\n",
        "    self.pnginfo_upload_image.height = min(512, image.height)\n",
        "    self.pnginfo_prompt_textarea.value = parameter_text\n",
        "    \n",
        "    # サムネイルを作成、parameter_textをそのまま保存\n",
        "    resize = 0.25\n",
        "    thumbnail = create_thumbnail(image=image, resize=resize)\n",
        "    with io.BytesIO() as buf:\n",
        "      save_image(thumbnail, buf, parameter_text)\n",
        "      self.thumbnail_image.width = min(512, image.width*resize)\n",
        "      self.thumbnail_image.height = min(512, image.height*resize)\n",
        "      self.thumbnail_image.value = buf.getvalue()\n",
        "    \n",
        "    # ロード直後は常にedit無効\n",
        "    self.enable_edit_check.value = False\n",
        "\n",
        "  \"\"\"\n",
        "  \"send to **\"ボタン押下時にそれぞれのペインへ反映させる\n",
        "  \"\"\"\n",
        "  def on_send_to_txt2img(self, remove):\n",
        "    # TODO: should be event-driven\n",
        "    new_info = GeneratedFileInfo.from_parameter_text(self.pnginfo_prompt_textarea.value)\n",
        "    new_info.imageBytes = self.pnginfo_upload_image.value\n",
        "    self.info = new_info\n",
        "    txt2imgPane.reflectPNGInfo(self.info)\n",
        "\n",
        "  def on_send_to_img2img(self, remove):\n",
        "    # TODO: should be event-driven\n",
        "    new_info = GeneratedFileInfo.from_parameter_text(self.pnginfo_prompt_textarea.value)\n",
        "    new_info.imageBytes = self.pnginfo_upload_image.value\n",
        "    self.info = new_info\n",
        "    img2imgPane.reflectPNGInfo(self.info)\n",
        "\n",
        "  def on_send_to_inpaint(self, remove):\n",
        "    # TODO: should be event-driven\n",
        "    new_info = GeneratedFileInfo.from_parameter_text(self.pnginfo_prompt_textarea.value)\n",
        "    new_info.imageBytes = self.pnginfo_upload_image.value\n",
        "    self.info = new_info\n",
        "    inpaintPane.reflectPNGInfo(self.info)\n",
        "\n",
        "  # check時に編集の有効を切り替える\n",
        "  def on_enable_edit_check(self, change):\n",
        "    self.pnginfo_prompt_textarea.disabled = not change.new\n",
        "\n",
        "  def on_edit_save(self, remove):\n",
        "    img = Image.open(io.BytesIO(self.pnginfo_upload_image.value))\n",
        "    with io.BytesIO() as buf:\n",
        "      save_image(img, buf, self.pnginfo_prompt_textarea.value)\n",
        "      self.pnginfo_upload_image.value = buf.getvalue()\n",
        "\n",
        "  def on_edit_save_thumbnail(self, remove):\n",
        "    img = Image.open(io.BytesIO(self.thumbnail_image.value))\n",
        "    with io.BytesIO() as buf:\n",
        "      save_image(img, buf, self.pnginfo_prompt_textarea.value)\n",
        "      self.thumbnail_image.value = buf.getvalue()\n",
        "\n",
        "#PNGInfoペインのインスタンスを生成\n",
        "pnginfoPane = PnginfoPaneView(txt2imgPane, img2imgPane, inpaintPane)\n"
      ],
      "metadata": {
        "id": "6oXeeOgn74tr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Extrasタブ内の共通GUI\n",
        "\n",
        "from google.colab import files\n",
        "import subprocess\n",
        "\n",
        "class ExtrasSubTab:\n",
        "  def __init__(self, parent, root):\n",
        "    self.parent = parent\n",
        "    self.rootDir = root\n",
        "    self.inputDir = os.path.join(root, 'Input')\n",
        "    self.outputDir = os.path.join(root, 'Output')\n",
        "    self.weightsDir = os.path.join(root, 'weights')\n",
        "    # 入力ディレクトリを作成\n",
        "    if os.path.exists(self.inputDir) == False:\n",
        "      os.mkdir(self.inputDir)\n",
        "    # 出力先ディレクトリを作成\n",
        "    if os.path.exists(self.outputDir) == False:\n",
        "      os.mkdir(self.outputDir)\n",
        "\n",
        "    self.generate_button = widgets.Button()\n",
        "    self.generate_button.on_click(self.on_generate)\n",
        "    self.outputWindow = widgets.Output()\n",
        "    self.settingPane = None # 具体的な設定のGUI\n",
        "\n",
        "    self.upload_button = widgets.Button()\n",
        "    self.upload_button.on_click(self.on_upload)\n",
        "    self.output_file_select = widgets.SelectionSlider(options=[\"keep\", \"remove\"], value=\"remove\")\n",
        "    self.input_file_select = widgets.SelectionSlider(options=[\"keep\", \"remove\"], value=\"remove\")\n",
        "\n",
        "    self.remove_input_file_check = widgets.Checkbox(value=True) # 生成後に入力ファイルを消す\n",
        "    self.remove_output_file_check = widgets.Checkbox(value=True) # 生成前に出力ファイルを消す\n",
        "    self.download_button = widgets.Button()\n",
        "    self.download_button.on_click(self.on_download)\n",
        "\n",
        "  # 設定項目のGUIを返すよう派生クラスで実装する\n",
        "  def set_setting_layout(self):\n",
        "    pass\n",
        "\n",
        "  # 生成処理を派生クラスで実装する\n",
        "  def generate(self):\n",
        "    pass\n",
        "  \n",
        "  def set_layout(self):\n",
        "    self.generate_button.layout=Layout(width=\"50%\")\n",
        "    self.generate_button.description=\"generate\"\n",
        "    self.generate_button.style={\"button_color\":\"lightskyblue\"}\n",
        "    self.upload_button.description=\"upload images\"\n",
        "    self.download_button.description=\"download zip\"\n",
        "\n",
        "    self.output_file_select.description=\"Output files before generating\"\n",
        "    self.output_file_select.style={\"description_width\": \"16em\"}\n",
        "    self.output_file_select.layout=Layout(width=\"23em\")\n",
        "\n",
        "    self.input_file_select.description=\"Input files after generating\"\n",
        "    self.input_file_select.style={\"description_width\": \"16em\"}\n",
        "    self.input_file_select.layout=Layout(width=\"23em\")\n",
        "\n",
        "    setting_tab = widgets.Tab(layout = Layout(width=\"auto\",height=\"auto\"), children=[self.set_setting_layout()])\n",
        "    setting_tab.set_title(0, \"param\")\n",
        "\n",
        "    self.layout = \\\n",
        "    widgets.VBox(layout=Layout(width=\"100%\", height=\"100%\"), children=[\n",
        "      widgets.HBox(children=[\n",
        "        #self.src_uploader.set_layout(),\n",
        "        widgets.Box(layout=Layout(width=\"50%\", height=\"auto\"), children=[\n",
        "          widgets.VBox([\n",
        "            widgets.HBox([self.upload_button, widgets.Label(value=\"(popup to the right window)\")]),\n",
        "            widgets.HBox([self.output_file_select, self.input_file_select]),\n",
        "            setting_tab,\n",
        "            widgets.HBox([self.generate_button], layout=Layout(width=\"auto\", height=\"auto\", margin=\"1em 0\") ),\n",
        "            self.download_button,\n",
        "          ]),\n",
        "        ]),\n",
        "        widgets.Box([self.outputWindow],layout=Layout(width=\"50%\", height=\"20em\", border=\"gray solid 1px\")), # output\n",
        "      ]),\n",
        "    ])\n",
        "    return self.layout\n",
        "\n",
        "  def on_generate(self, remove):\n",
        "    remove_output = (self.output_file_select.value == \"remove\")\n",
        "    remove_input = (self.input_file_select.value == \"remove\")\n",
        "\n",
        "    self.outputWindow.clear_output()\n",
        "    with self.outputWindow:\n",
        "      # 生成前に出力ファイルを消す\n",
        "      if remove_output == True:\n",
        "        subprocess.run(f\"rm {self.outputDir}/*\", shell=True)\n",
        "\n",
        "      self.generate()\n",
        "\n",
        "      # 生成後に入力ファイルを消す\n",
        "      if remove_input == True:\n",
        "        subprocess.run(f\"rm {self.inputDir}/*\", shell=True)\n",
        "\n",
        "  def on_upload(self, remove):\n",
        "    with self.outputWindow:\n",
        "      # colabの機能を使ってアップロードされたファイルを受け取る\n",
        "      uploaded = files.upload()\n",
        "      for filename in uploaded.keys():\n",
        "        # ファイルをInputディレクトリに移動\n",
        "        subprocess.run(f\"mv {filename} {self.inputDir}\", shell=True)\n",
        "\n",
        "  # Outputディレクトリの中身を1個のzipファイルにまとめ、ダウンロード。\n",
        "  # Colabでは一度に1ファイルしかダウンロードできない。\n",
        "  # 複数ファイルを1個のzipファイルにまとめることで、実質的に複数ファイルを一度でダウンロードできる\n",
        "  def on_download(self, remove):\n",
        "    with self.outputWindow:\n",
        "      # Outputディレクトリの中身を1個のzipファイルにまとめる\n",
        "      zipfile = f\"{self.rootDir}/Output.zip\"\n",
        "      subprocess.run(f\"rm {zipfile}\", shell=True)\n",
        "      subprocess.run(f\"zip -r -j {zipfile} {self.outputDir}\", shell=True)\n",
        "      # colabの機能を使ってダウンロード\n",
        "      files.download(zipfile)\n"
      ],
      "metadata": {
        "id": "NMceCGooSSOV",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Extrasタブ／高解像度化処理\n",
        "\n",
        "# HighResタブ（高解像度化）\n",
        "class HighResRealESR(ExtrasSubTab):\n",
        "  def __init__(self, parent, root):\n",
        "    super().__init__(parent, root)\n",
        "    self.model_select = widgets.Dropdown(description=\"model\", options=[ \"RealESRGAN_x4plus\", \"RealESRNet_x4plus\", \"RealESRGAN_x4plus_anime_6B\", \"RealESRGAN_x2plus\", \"realesr-animevideov3\", \"realesr-general-x4v3\"], value=\"RealESRGAN_x4plus\" )\n",
        "    self.scale_slider = widgets.FloatSlider(min=0, max=4.0, value=4.0)\n",
        "    self.face_enhance_check = widgets.Checkbox(value=False)\n",
        "  \n",
        "  def set_setting_layout(self):\n",
        "    self.scale_slider.description=\"scale\"\n",
        "    self.face_enhance_check.description=\"face enhance\"\n",
        "    return widgets.VBox([\n",
        "      self.model_select,\n",
        "      self.scale_slider,\n",
        "      self.face_enhance_check,\n",
        "    ])\n",
        "\n",
        "  # 高解像度化画像を生成\n",
        "  # https://github.com/xinntao/Real-ESRGAN/inference_realesrgan.py からコピーして一部変更\n",
        "  def generate(self):\n",
        "    #!python inference_realesrgan.py -n RealESRGAN_x4plus -i upload -o results --outscale {self.scale_slider.value} {--face_enhance}\n",
        "\n",
        "    # パラメータ\n",
        "    model_path = None\n",
        "    outscale = self.scale_slider.value\n",
        "    face_enhance = self.face_enhance_check.value\n",
        "\n",
        "    #TODO: support setting of these parameters\n",
        "    dni_weight = None\n",
        "    denoise_strength = 1\n",
        "    tile=0\n",
        "    tile_pad=10\n",
        "    pre_pad=0\n",
        "    half=torch.cuda.is_available() #True #fp16\n",
        "    gpu_id=None\n",
        "    suffix = 'out' #出力ファイル名の末尾につける文字列。 foobar_{suffix}.{ext} のようなファイル名になる\n",
        "    ext = 'auto' # 出力ファイルの拡張子\n",
        "\n",
        "    # determine models according to model names\n",
        "    model_name = self.model_select.value\n",
        "    if model_name == 'RealESRGAN_x4plus':  # x4 RRDBNet model\n",
        "        model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=4)\n",
        "        netscale = 4\n",
        "        file_url = ['https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth']\n",
        "    elif model_name == 'RealESRNet_x4plus':  # x4 RRDBNet model\n",
        "        model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=4)\n",
        "        netscale = 4\n",
        "        file_url = ['https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.1/RealESRNet_x4plus.pth']\n",
        "    elif model_name == 'RealESRGAN_x4plus_anime_6B':  # x4 RRDBNet model with 6 blocks\n",
        "        model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=6, num_grow_ch=32, scale=4)\n",
        "        netscale = 4\n",
        "        file_url = ['https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.2.4/RealESRGAN_x4plus_anime_6B.pth']\n",
        "    elif model_name == 'RealESRGAN_x2plus':  # x2 RRDBNet model\n",
        "        model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=2)\n",
        "        netscale = 2\n",
        "        file_url = ['https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.1/RealESRGAN_x2plus.pth']\n",
        "    elif model_name == 'realesr-animevideov3':  # x4 VGG-style model (XS size)\n",
        "        model = SRVGGNetCompact(num_in_ch=3, num_out_ch=3, num_feat=64, num_conv=16, upscale=4, act_type='prelu')\n",
        "        netscale = 4\n",
        "        file_url = ['https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesr-animevideov3.pth']\n",
        "    elif model_name == 'realesr-general-x4v3':  # x4 VGG-style model (S size)\n",
        "        model = SRVGGNetCompact(num_in_ch=3, num_out_ch=3, num_feat=64, num_conv=32, upscale=4, act_type='prelu')\n",
        "        netscale = 4\n",
        "        file_url = [\n",
        "            'https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesr-general-wdn-x4v3.pth',\n",
        "            'https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesr-general-x4v3.pth'\n",
        "        ]\n",
        "    else:\n",
        "      # do nothing\n",
        "      print(f\"not registered model: '{model_name}'\")\n",
        "      return\n",
        "\n",
        "    # determine model paths\n",
        "    model_path = os.path.join(self.weightsDir, model_name + '.pth')\n",
        "    if not os.path.isfile(model_path):\n",
        "      for url in file_url:\n",
        "        # model_path will be updated\n",
        "        model_path = load_file_from_url( url=url, model_dir=self.weightsDir, progress=True, file_name=None )\n",
        "\n",
        "    # use dni to control the denoise strength\n",
        "    if model_name == 'realesr-general-x4v3' and denoise_strength != 1:\n",
        "      wdn_model_path = model_path.replace('realesr-general-x4v3', 'realesr-general-wdn-x4v3')\n",
        "      model_path = [model_path, wdn_model_path]\n",
        "      dni_weight = [denoise_strength, 1 - denoise_strength]\n",
        "\n",
        "    # restorer\n",
        "    # outscale は処理時に指定する\n",
        "    upsampler = RealESRGANer(\n",
        "      scale=netscale,\n",
        "      model_path=model_path,\n",
        "      dni_weight=dni_weight,\n",
        "      model=model,\n",
        "      tile=tile,\n",
        "      tile_pad=tile_pad,\n",
        "      pre_pad=pre_pad,\n",
        "      half=half,\n",
        "      gpu_id=gpu_id)\n",
        "\n",
        "    if face_enhance == True:  # Use GFPGAN for face enhancement\n",
        "      from gfpgan import GFPGANer\n",
        "      face_enhancer = GFPGANer(\n",
        "        model_path='https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth',\n",
        "        upscale=outscale,\n",
        "        arch='clean',\n",
        "        channel_multiplier=2,\n",
        "        bg_upsampler=upsampler)\n",
        "\n",
        "\n",
        "    paths = sorted( glob.glob(os.path.join(self.inputDir, '*')) )\n",
        "    for idx, path in enumerate(paths):\n",
        "      imgname, extension = os.path.splitext(os.path.basename(path))\n",
        "      print('Testing', idx, imgname)\n",
        "\n",
        "      img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
        "      if len(img.shape) == 3 and img.shape[2] == 4:\n",
        "        img_mode = 'RGBA'\n",
        "      else:\n",
        "        img_mode = None\n",
        "\n",
        "      try:\n",
        "        if face_enhance:\n",
        "          _, _, output = face_enhancer.enhance(img, has_aligned=False, only_center_face=False, paste_back=True)\n",
        "        else:\n",
        "          # outscaleを指定\n",
        "          output, _ = upsampler.enhance(img, outscale=outscale)\n",
        "      except RuntimeError as error:\n",
        "        print('Error', error)\n",
        "        print('If you encounter CUDA out of memory, try to set --tile with a smaller number.')\n",
        "      else:\n",
        "        if ext == 'auto':\n",
        "          extension = extension[1:]\n",
        "        else:\n",
        "          extension = ext\n",
        "        if img_mode == 'RGBA':  # RGBA images should be saved in png format\n",
        "          extension = 'png'\n",
        "        if suffix == '':\n",
        "          save_path = os.path.join(self.outputDir, f'{imgname}.{extension}')\n",
        "        else:\n",
        "          save_path = os.path.join(self.outputDir, f'{imgname}_{suffix}.{extension}')\n",
        "        cv2.imwrite(save_path, output)\n",
        "\n",
        "    print('complete.')\n"
      ],
      "metadata": {
        "id": "U06XSswdSuKt",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Extrasタブ／深度推定処理\n",
        "\n",
        "# DepthMapタブ（深度推定）\n",
        "class DepthMapMiDaS(ExtrasSubTab):\n",
        "  # 入力要素・出力要素の定義を行う。実際のレイアウトはset_layout()で設定\n",
        "  def __init__(self, parent, root):\n",
        "    super().__init__(parent, root)\n",
        "\n",
        "    # 公式のサンプル結果より、dpt_swin_large_384 をモデルに使用（椅子が2個とも深度推定できている、速度も悪くない）\n",
        "    # 他に dpt_next_vit_large_384 が候補\n",
        "    self.model_select = widgets.Dropdown(description=\"model\", options=[\n",
        "        \"dpt_beit_large_512\", \"dpt_beit_large_384\", \"dpt_beit_base_384\", \"dpt_swin2_large_384\",\n",
        "        \"dpt_swin2_base_384\", \"dpt_swin2_tiny_256\", \"dpt_swin_large_384\", \"dpt_next_vit_large_384\",\n",
        "        \"dpt_levit_224\", \"dpt_large_384\", \"dpt_hybrid_384\", \"midas_v21_384\", \"midas_v21_small_256\",\n",
        "        \"openvino_midas_v21_small_256\" ],\n",
        "        #value = \"dpt_beit_large_512\", #run.pyのデフォルト\n",
        "        value = \"dpt_swin_large_384\",\n",
        "    )\n",
        "\n",
        "  def set_setting_layout(self):\n",
        "    return widgets.VBox([\n",
        "      self.model_select,\n",
        "    ])\n",
        "\n",
        "  # 深度画像を生成\n",
        "  # https://github.com/isl-org/MiDaS/blob/master/run.py からコピーして一部変更\n",
        "  def generate(self):\n",
        "    #!python run.py --model_type <model_type> -model_weights <path/to/model.pt> --input_path input --output_path output\n",
        "\n",
        "    #パラメータ\n",
        "    model_type = self.model_select.value\n",
        "    side = False #default value is True\n",
        "\n",
        "    #TODO: support setting of these parameters\n",
        "    optimize = None #fp32\n",
        "    height = None\n",
        "    square = True\n",
        "    grayscale = True\n",
        "\n",
        "    model_path = self.download_model(model_type, self.weightsDir)\n",
        "    if model_path == None:\n",
        "      print(f\"not registered model type:{model_type}\")\n",
        "      return\n",
        "\n",
        "    print(\"Initialize\")\n",
        "\n",
        "    # select device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Device: %s\" % device)\n",
        "\n",
        "    model, transform, net_w, net_h = midas.model_loader.load_model(device, model_path, model_type, optimize, height, square)\n",
        "\n",
        "    # get input\n",
        "    if self.inputDir is not None:\n",
        "      image_names = glob.glob(os.path.join(self.inputDir, \"*\"))\n",
        "      num_images = len(image_names)\n",
        "    else:\n",
        "      print(\"No input path specified.\")\n",
        "      return\n",
        "\n",
        "    print(\"Start processing\")    \n",
        "\n",
        "    for index, image_name in enumerate(image_names):\n",
        "\n",
        "      print(\"  Processing {} ({}/{})\".format(image_name, index + 1, num_images))\n",
        "\n",
        "      # input\n",
        "      original_image_rgb = utils.read_image(image_name)  # in [0, 1]\n",
        "      image = transform({\"image\": original_image_rgb})[\"image\"]\n",
        "\n",
        "      # compute\n",
        "      with torch.no_grad():\n",
        "        prediction = process(device, model, model_type, image, (net_w, net_h), original_image_rgb.shape[1::-1],\n",
        "                              optimize, False)\n",
        "\n",
        "      # output\n",
        "      if self.outputDir is not None:\n",
        "        filename = os.path.join(\n",
        "          self.outputDir, os.path.splitext(os.path.basename(image_name))[0] + '-' + model_type\n",
        "        )\n",
        "        if not side:\n",
        "          utils.write_depth(filename, prediction, grayscale, bits=2)\n",
        "        else:\n",
        "          original_image_bgr = np.flip(original_image_rgb, 2)\n",
        "          content = create_side_by_side(original_image_bgr*255, prediction, grayscale)\n",
        "          cv2.imwrite(filename + \".png\", content)\n",
        "        utils.write_pfm(filename + \".pfm\", prediction.astype(np.float32))\n",
        "\n",
        "    print(\"Finished\")\n",
        "\n",
        "\n",
        "  #モデルをダウンロードしてパスを得る\n",
        "  def download_model(self, model_type, weights_dir):\n",
        "    model_path_dict = {\n",
        "      \"dpt_beit_large_512\": [\"v3_1\", []],\n",
        "      \"dpt_beit_large_384\": [\"v3_1\", []],\n",
        "      \"dpt_beit_base_384\": [\"v3_1\", []],\n",
        "      \"dpt_swin2_large_384\": [\"v3_1\", []],\n",
        "      \"dpt_swin2_base_384\": [\"v3_1\", []],\n",
        "      \"dpt_swin2_tiny_256\": [\"v3_1\", []],\n",
        "      \"dpt_swin_large_384\": [\"v3_1\", []],\n",
        "      \"dpt_next_vit_large_384\": [\"v3_1\", []],\n",
        "      \"dpt_levit_224\": [\"v3_1\", []],\n",
        "      \"dpt_large_384\": [\"v3\", []],\n",
        "      \"dpt_hybrid_384\": [\"v3\", []],\n",
        "      \"midas_v21_384\": [\"v2_1\", []],\n",
        "      \"midas_v21_small_256\": [\"v2_1\", []],\n",
        "      \"openvino_midas_v21_small_256\": [\"v3_1\", [\"openvino_midas_v21_small_256.xml\", \"openvino_midas_v21_small_256.bin\"] ]\n",
        "      }\n",
        "    model_path = \"\"\n",
        "    filename = \"\"\n",
        "    url_root = \"https://github.com/isl-org/MiDaS/releases/download\"\n",
        "\n",
        "    if model_type in model_path_dict.keys():\n",
        "      if len(model_path_dict[model_type][1]) == 0:\n",
        "        filename = f\"{model_type}.pt\"\n",
        "        filelist = [filename]\n",
        "        model_path = os.path.join(weights_dir, filename)\n",
        "      else:\n",
        "        # for openvino\n",
        "        filelist = model_path_dict[model_type][1]\n",
        "        model_path = os.path.join(weights_dir, filelist[0] ) #.xml file\n",
        "    else:\n",
        "      return None\n",
        "    \n",
        "    if not os.path.isfile(model_path):\n",
        "      for filename in filelist:\n",
        "        url = '/'.join( [url_root, model_path_dict[model_type][0], filename] )   # https://github.com/isl-org/MiDaS/releases/download/v3_1/dpt_beit_large_512.pt\n",
        "        local = os.path.join(weights_dir, filename)  # /content/MiDaS/weights/dpt_beit_large_512.pt\n",
        "        print(url, local)\n",
        "        torch.hub.download_url_to_file( url=url, dst=local, progress=True )\n",
        "    \n",
        "    return model_path\n",
        "\n"
      ],
      "metadata": {
        "id": "TEmXgh1aK1UL",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Extras全体のタブ\n",
        "class ExtraTabView:\n",
        "  def __init__(self):\n",
        "    self.highResTab = HighResRealESR(self, HighRes_root)\n",
        "    self.depthMapTab = DepthMapMiDaS(self, DepthMap_root)\n",
        "\n",
        "  def set_layout(self):\n",
        "    #Extra全体のサブメニューを収めるタブを生成\n",
        "    top_tab_dict = {\"HighRes\":self.highResTab.set_layout(), \"DepthMap\":self.depthMapTab.set_layout() }\n",
        "    top_tab = widgets.Tab(layout = Layout(width=\"100%\",height=\"100%\"))\n",
        "\n",
        "    #各タブのタイトルを設定\n",
        "    top_tab.children = list(top_tab_dict.values())\n",
        "    for i,title in enumerate(top_tab_dict.keys()):\n",
        "      top_tab.set_title(i, title)\n",
        "    \n",
        "    self.layout = \\\n",
        "    widgets.HBox(layout=Layout(width=\"100%\", height=\"100%\"), children=[\n",
        "      top_tab\n",
        "    ])\n",
        "    return self.layout\n",
        "\n",
        "#Extraタブのインスタンスを生成\n",
        "extraTab = ExtraTabView()\n"
      ],
      "metadata": {
        "id": "25Tw5PLzKsA0",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 全体レイアウト\n",
        "\n",
        "# トップメニュータブと各ペインを設定\n",
        "top_tab_dict = {\"setup\":setupPane.set_layout(), \"txt2img\":txt2imgPane.set_layout(), \"img2img\":img2imgPane.set_layout(), \"inpaint\":inpaintPane.set_layout(), \"PNG Info\":pnginfoPane.set_layout(), \"Extras\":extraTab.set_layout(), }\n",
        "sharedBackEnd.setupPane = setupPane\n",
        "sharedBackEnd.txt2imgPane = txt2imgPane\n",
        "sharedBackEnd.img2imgPane = img2imgPane\n",
        "sharedBackEnd.inpaintPane = inpaintPane\n",
        "sharedBackEnd.pnginfoPane = pnginfoPane\n",
        "\n",
        "\n",
        "top_tab = widgets.Tab(layout = Layout(width=\"100%\",height=\"100%\"))\n",
        "top_tab.children = list(top_tab_dict.values())\n",
        "for i,title in enumerate(top_tab_dict.keys()):\n",
        "  top_tab.set_title(i, title)\n",
        "\n",
        "# メインウィンドウを生成\n",
        "main_window = widgets.Box([top_tab], layout = Layout(width=\"100%\",height=\"100%\"))"
      ],
      "metadata": {
        "id": "tjTx1gqT8Gzz",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. 起動"
      ],
      "metadata": {
        "id": "B4ktEz5qAHEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title GUIを起動。「出力を全画面表示」を推奨\n",
        "main_window"
      ],
      "metadata": {
        "id": "3YO9L5gz3_sx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}